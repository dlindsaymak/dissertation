---
date: "`r Sys.Date()`" #Project Page - DEEP CTN Scale
external_link: ""
summary: Creating & Validating the DEEP CTN Scale.
tags:
  - Connection to Nature
  - DEEP CTN Scale
  - Pro-Environmental Behavior
  - Well-being
title: DEEP CTN Scale
links:
  - name: OSF Project
    url: "https://osf.io/5xbvp/" 
type: page
output:
  blogdown::html_page:
    toc: true
draft: false
editor_options: 
  markdown: 
    wrap: 72
diagram: true
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, echo = FALSE)
```

```{r loading, include=FALSE, echo=FALSE}
#loading packages
library(tidyverse)
library(lubridate)
library(flextable)
library(moments) #skewness & kurtosis
library(lavaan) #CFA 
library(corrplot) #correlations
library(MVN) #test of normality
library(semPlot) #plotting paths in CFA
library(Hmisc) #correlations 
library(car) # Type 2 Anova
library(effectsize)
library(relaimpo) #calculates unique variance
library(ggplot2) #grid arrange plots
library(knitr) # has kable() to generate simple tables

#flextable defaults
set_flextable_defaults(digits = 2, layout = "autofit", width = 1)
                      

#Loading data
data <- 
  read_csv("cfa_prolific_jan24.csv")

### Data cleaning
#Delete top two rows
data <- data[-c(1:2),]

#remove test subjects
#any participant recorded before 29 Jan 2023, 10.14am
data <- 
  data %>% 
  mutate(EndDate = ymd_hms(EndDate)) %>%
  filter(RecordedDate > "2024-01-29 10:14:00 UTC")

n_recruited <- length(unique(data$PROLIFIC_PID))

#remove participants who did not complete the survey
data <- 
  data %>% 
  filter(Progress == "100")

n_completed <- length(unique(data$PROLIFIC_PID))

#Attention checks
#att_1[2] -> must answer 2 to pass
#att_2[6] -> must answer 6 to pass
#att_3[5] -> must answer 5 to pass

data <- 
  data %>% 
  mutate(
    `att_1[2]` = ifelse(`att_1[2]` == "2", 1, 0),
    `att_2[6]` = ifelse(`att_2[6]` == "6", 1, 0),
    `att_3[5]` = ifelse(`att_3[5]` == "5", 1, 0),
    att_total = `att_1[2]` + `att_2[6]` + `att_3[5]`
  ) 

data %>% 
  group_by(att_total) %>%
  summarise(n = length(PROLIFIC_PID))

#remove participants who failed 1 or more attention checks
data <- 
  data %>% 
  filter(att_total >= 2)

n_passed <- length(unique(data$PROLIFIC_PID))

#remove participants who reported not paying attention or answering honestly in the subjective attention/validity check
#keep the two top answers
data <- 
  data %>% 
  filter(attention...146 == "1" | attention...146 == "2")

n_valid <- length(unique(data$PROLIFIC_PID))

```

Data collected on 29 Jan 2024

``` mermaid

  graph LR;
  A[N recruited via Prolific: `r n_recruited`] --> B
  B[N completed survey: `r n_completed`] --> C
  C[N passed attention checks:`r n_passed`] --> D[N reported honestly: `r n_valid`]
```

```{r demographics, echo=FALSE, include=FALSE}
#dummycode gender
#man = 0; woman = 1; other = NA (will remove these from analysis as there isn't enough for sufficient power)
data <-
  data %>% 
  mutate(age = as.numeric(age),
         gender = factor(as.numeric(gender), 
                         levels = c("1", "2", "3", "4", "5", "6", "7"),
                         labels = c("Man", "Woman", "Trans Man", "Trans Woman", "Non-binary", "Other", "No response")),
         gender_dummy = dplyr::case_when(gender == "Man" ~ 0,
                                         gender == "Woman" ~ 1,
                                         .default = NA),
         race = factor(as.numeric(ethnoracial),
                       levels = c("1", "2", "3", "4", "5", "6", "7", "8", "9"),
                       labels = c("Asian", "White", "Hispanic or Latino", "Black or African American", "Middle Eastern or North African", "Native Hawaiian or other Pacific Islander", "First Nation or Indigenous American", "Mixed", "No response")))

gender_sum <- 
data %>% 
  group_by(gender) %>% 
  summarise(n = length(id),
            perc = (n/n_valid)*100)

  race_sum <- 
  data %>% 
  group_by(race) %>% 
  summarise(n = length(id),
            perc = (n/n_valid)*100) %>% 
  arrange(dplyr::desc(perc))

  race_table <-   
  race_sum %>% 
    flextable() %>% 
    set_header_labels(race = "Race", n = "N", perc = "%") %>%
    colformat_double(j = "perc", digits = 2) %>% 
    autofit()


```

# Demographics

Mean age: `r round(mean(data$age, na.rm = TRUE),2)` years old (SD =
`r round(sd(data$age, na.rm = TRUE),2)`); range:
`r range(data$age, na.rm = T)`

```{r demographic plots, echo=FALSE, fig.height=5, fig.width=10}

gender_plot <-
data %>% 
  ggplot(aes(x = gender)) +
  geom_bar(aes(fill = gender), color = "#003300") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none",
        panel.background = element_blank()) +
  scale_fill_brewer(palette = "Greens")

race_plot <-
data %>% 
  ggplot(aes(x = race)) +
  geom_bar(aes(fill = race), color = "#003300") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none",
        panel.background = element_blank()) +
  scale_fill_brewer(palette = "Greens")

#set up so these plots are side by side
gridExtra::grid.arrange(gender_plot, race_plot, ncol = 2)


  
```

```{r CFA Dataframe, include=FALSE, echo=FALSE}

#create database of CTN items & change all items to numeric
items <- 
  data %>%
  dplyr::select(starts_with("CTN")) %>%
  mutate_all(as.numeric)

item_names <-
  c("I view nature as a mother who nurtures and cares for me",
    "Human beings and nature are connected by the same energy or Life-force",
    "My connection to nature is something I would describe as *spiritual*",
    "Every part of nature is sacred",
    "I have great respect for being alive on this earth and part of the universe",
    "I like the idea that, when I die, my body will return to the earth, nourishing the soil",
    "I like to get outdoors whenever I get the chance",
    "I feel uneasy if I am away from nature for too long",
    "I engage and participate with nature to find meaning and richness in life",
    "I think about the *shared breath* between myself and plants; I breathe in the oxygen released by plants, and plants use the carbon dioxide I exhale",
    "I often think about the fact that all life is grounded on this planet that is revolving around the sun",
    "Indoor plants are part of the family",
    "My favorite place is in nature",
    "Walking through a forest makes me forget about my daily worries",
    "I prefer outdoor to indoor sports",
    "Listening to the sounds of nature makes me relax",
    "Seeing a cleared forest is upsetting to me",
    "If one of my plants died, I would blame myself",
    "Thinking of someone carving their initials into a tree makes me cringe",
    "If there is an insect, such as a fly or a spider, in my home, I try to catch and release it rather than kill it",
    "When I eat, I feel thankful for the animals, plants, and earth for nourishing me",
    "I hike or run in nearby nature",
    "I take time to watch the clouds pass by",
    "I deliberately take time to watch stars at night",
    "When possible, I take time to watch the sunrise or the sunset without distractions",
    "I consciously watch or listen to birds",
    "I take time to consciously smell flowers",
    "I pay attention to the current phase of the moon",
    "I am careful to not step on snails",
    "I talk to the wild animals I encounter (e.g., birds, lizards, rabbits, squirrels)")


deepscaleitems <- 
  data_frame(variable.names(items), item_names) %>% 
     print(n = Inf) %>% 
     dplyr::rename(Code  = `variable.names(items)`,
            Items = item_names)


  

```

# Confirmatory Factor Analysis

## CFA Preparation

Before conducting the CFA we tested the assumptions of CFA models to
show multivariate normality via acceptable Mardia’s skewness and
kurtosis values. We used the general guidelines that the closer to zero
both skewness and kurtosis values, the closer to a normal
distribution. Any item whose skewness value was greater than \|1\|
and/or kurtosis value was greater than \|3\|, were considered non-normal
(either strongly skewed or having peaked or flat kurtosis) would be
removed from the analysis (Hair et al., 2017, p. 61).

Three items showed high negative skew high kurtosis and were removed
from further analysis (see Table 1 for details)[^1]. These items were
also found to be extremes in the pilot studies.

```{r Skewness kurtosis, message=FALSE, warning=FALSE, include=FALSE}
#detect skew items 
skew <- as.data.frame(round(sort(skewness(items),decreasing = T),2))

#pull information of extremely skewed items
skewed_items <- 
skew %>% 
  rename("skew" = "round(sort(skewness(items), decreasing = T), 2)") %>% 
  filter(skew > 1 | skew < -1)

skew_table <- 
  skewed_items %>% 
  rownames_to_column("Code") %>% 
  left_join(deepscaleitems, by = "Code") %>%
  mutate(kurtosis = NA, Data = NA) %>% 
  dplyr::select(Code, Items, skew, kurtosis, Data)


#detect kurtosis items
kurtosis <- as.data.frame(round(sort(kurtosis(items),
     decreasing=T),2))

#pull information of extreme kurtosis items
kurtosis_items <- 
kurtosis %>% 
  rename("kurtosis" = "round(sort(kurtosis(items), decreasing = T), 2)") %>% 
  filter(kurtosis > 3.1 | kurtosis < -3.1) 

kurtosis_table <-
  kurtosis_items %>% 
  rownames_to_column("Code") %>% 
  left_join(deepscaleitems, by = "Code") %>%
  mutate(skew = NA, Data = NA) %>% 
  dplyr::select(Code, Items, skew, kurtosis, Data)

#table of the extreme items
extremetable <- 
  bind_rows(skew_table, kurtosis_table) %>% 
  group_by(Code) %>% 
  summarise_all(~first(na.omit(.)))

#pulling out the extreme codes
extremes <-extremetable$Code

#data for the extreme items
extreme_data <- 
  items %>% 
  dplyr::select(extremes) %>% 
  pivot_longer(cols = everything(), names_to = "Code", values_to = "Data") %>% 
    left_join(deepscaleitems, by = "Code") %>%
  group_by(Code, Items) %>% 
  summarise(Data = list(Data)) %>% 
  mutate(skew = NA, kurtosis = NA) %>% 
  dplyr::select(Code, Items, skew, kurtosis, Data)

#merging data and extreme item kurtosis and skewness scores
extremetable <- 
  extremetable %>% 
  arrange(skew) %>% 
  left_join(extreme_data, by = "Code") %>% 
  dplyr::select(Code, Items.x, skew.x, kurtosis.x, Data.y) %>% 
  rename(Items = Items.x, skew = skew.x, kurtosis = kurtosis.x, Data = Data.y) 


  
items <- # remove extreme skew and kurtosis items from the data frame
  items %>% 
  dplyr::select(-c(extremes))

```

**Table 1. Items removed due to extreme skew & kurtosis**

```{r extreme items table, echo=FALSE, message=FALSE, warning=FALSE}
flextable(extremetable) %>% 
  mk_par(j = "Data", value = as_paragraph(
    plot_chunk(value = Data, type = "box")
  ) ) %>% 
  autofit()

```

Zero order correlations for all items were calculated to ensure that
items within a factor are not too weakly (r \< 0.30) correlated, and
that items between factors are not too strongly (r \> 0.75) correlated.

One item had consistently low correlation with other items in its
expected factor (CTN_EMO_2: "If one of my plants died, I would blame
myself"). This item was retained as the emotional factor was already
reduced to 4 items. No items had high correlations with other items in
other factors.

```{r Correlation plots within, include=FALSE, out.width="100%"}
# Deep
deep_items <-
  items %>% 
  dplyr::select(CTN_spirit_1,
         CTN_spirit_2,
         CTN_spirit_3,
         CTN_spirit_4,
         CTN_spirit_6,
         CTN_spirit_7,
         CTN_spirit_8,
         CTN_spirit_9,
         CTN_spirit_10) %>% 
  as.matrix()

deep_cor <-
  rcorr(deep_items, type = "spearman")
deep_row = rownames(deep_cor$r)
deep_m = t(combn(deep_row, 2))
deep_d = cbind(data.frame(deep_m), R = deep_cor$r[deep_m], P = deep_cor$P[deep_m])
deep_d$label = round(deep_d$R, 2)
deep_d$label[deep_d$P < 0.001] = paste0(deep_d$label[deep_d$P < 0.001], "\n***")
deep_d$X1 = factor(deep_d$X1, deep_row)
deep_d$X2 = factor(deep_d$X2, rev(deep_row))
graphics.off()
deep_plot <- 
  deep_d %>% 
  ggplot(aes(X1, X2, fill = R, label = label)) +
    geom_tile(color = "white") +
    scale_fill_viridis_c(begin = 1, end = 0) +
    geom_text(color = ifelse(deep_d$R < 0.60, "black", "white")) +
    theme_bw() +
    coord_equal() +
     theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Experiential
exp_items <-
  items %>% 
  dplyr::select(CTN_exp_1,
                CTN_exp_2,
                CTN_exp_3,
                CTN_exp_4,
                CTN_exp_5,
                CTN_exp_6,
                CTN_exp_8) %>% 
  as.matrix()

exp_cor <-
  rcorr(exp_items, type = "spearman")
exp_row = rownames(exp_cor$r)
exp_m = t(combn(exp_row, 2))
exp_d = cbind(data.frame(exp_m), R = exp_cor$r[exp_m], P = exp_cor$P[exp_m])
exp_d$label = round(exp_d$R, 2)
exp_d$label[exp_d$P < 0.001] = paste0(exp_d$label[exp_d$P < 0.001], "\n***")
exp_d$X1 = factor(exp_d$X1, exp_row)
exp_d$X2 = factor(exp_d$X2, rev(exp_row))
graphics.off()
exp_plot <- 
  exp_d %>% 
  ggplot(aes(X1, X2, fill = R, label = label)) +
    geom_tile(color = "white") +
    scale_fill_viridis_c(begin = 1, end = 0) +
    geom_text(color = ifelse(exp_d$R < 0.60, "black", "white")) +
    theme_bw() +
    coord_equal() +
     theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Emotional
emo_items <- 
  items %>% 
  dplyr::select(CTN_emo_1,
                CTN_emo_2,
                CTN_emo_3,
                CTN_emo_4,
                CTN_emo_6) %>% 
  as.matrix()

emo_cor <-
  rcorr(emo_items, type = "spearman")
emo_row = rownames(emo_cor$r)
emo_m = t(combn(emo_row, 2))
emo_d = cbind(data.frame(emo_m), R = emo_cor$r[emo_m], P = emo_cor$P[emo_m])
emo_d$label = round(emo_d$R, 2)
emo_d$label[emo_d$P < 0.001] = paste0(emo_d$label[emo_d$P < 0.001], "\n***")
emo_d$X1 = factor(emo_d$X1, emo_row)
emo_d$X2 = factor(emo_d$X2, rev(emo_row))
graphics.off()
emo_plot <- 
  emo_d %>% 
  ggplot(aes(X1, X2, fill = R, label = label)) +
    geom_tile(color = "white") +
    scale_fill_viridis_c(begin = 1, end = 0) +
    geom_text(color = ifelse(emo_d$R < 0.60, "black", "white")) +
    theme_bw() +
    coord_equal() +
     theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Presence
presence_items <-
  items %>% 
  dplyr::select(CTN_mind_1, 
                CTN_mind_2,
                CTN_mind_3,
                CTN_mind_4,
                CTN_mind_5,
                CTN_mind_6)%>% 
  as.matrix()

pres_cor <-
  rcorr(presence_items, type = "spearman")
pres_row = rownames(pres_cor$r)
pres_m = t(combn(pres_row, 2))
pres_d = cbind(data.frame(pres_m), R = pres_cor$r[pres_m], P = pres_cor$P[pres_m])
pres_d$label = round(pres_d$R, 2)
pres_d$label[pres_d$P < 0.001] = paste0(pres_d$label[pres_d$P < 0.001], "\n***")
pres_d$X1 = factor(pres_d$X1, pres_row)
pres_d$X2 = factor(pres_d$X2, rev(pres_row))
graphics.off()
pres_plot <- 
  pres_d %>% 
  ggplot(aes(X1, X2, fill = R, label = label)) +
    geom_tile(color = "white") +
    scale_fill_viridis_c(begin = 1, end = 0) +
    geom_text(color = ifelse(pres_d$R < 0.60, "black", "white")) +
    theme_bw() +
    coord_equal() +
     theme(axis.text.x = element_text(angle = 45, hjust = 1))

#set up so these plots are in a grid
gridExtra::grid.arrange(deep_plot, exp_plot, emo_plot, pres_plot, ncol = 2)

#emo_d %>% 
#  dplyr::select(X1, X2, R, P) %>%
#  filter(R < .30) %>% 
#  flextable() %>% 
#  colformat_double(j = 3:4, digits = 2) %>%
#  autofit()
```

```{r Correlations Large, echo=FALSE}
#items <-
#  items %>% 
#  dplyr::select(-CTN_emo_2)

high_cor <- 
items %>% 
    dplyr::select_if(is.numeric) %>%
    cor() %>% 
    round(digits = 2) %>%
    as.data.frame() %>%
    rownames_to_column %>%
    gather(colname, value, -rowname) %>%
    group_by(rowname) %>%
  filter(abs(value) >= 0.75) %>%
  filter(abs(value) != 1)
```

To ensure the correct rotation method was used, tests of multivariate
and univariate normality were conducted. Using the MVN package in R, a
Mardia test of multivariate and univariate normality found that this
data is not normal distributed [@MVN]. As such, we chose to use a
rotation-method that is robust to non-normal data. However, normality is
not considered a critical assumption for factor analysis [@garson2022a,
p 22].

```{r Mardia Test, include=FALSE}
norm_result <- 
  items %>% 
  mvn(mvnTest="mardia",  
    univariateTest="SW")

norms <- 
norm_result$multivariateNormality

norms <-
norms %>% 
 rename(p = `p value`) %>% 
  mutate(p = format.pval(as.numeric(as.character(p)), eps = .001,
                         scientific = F)) %>% 
  mutate(Statistic = round(as.numeric(as.character(Statistic)),2)) %>% 
  flextable() %>% 
  autofit()
```

**Table 2. Items tested for the DEEP Connection to Nature Scale**

```{r Final Items, echo=FALSE, warning=FALSE}

final_items <-
  items %>% 
  colnames()

ctnflex <-
deepscaleitems %>% 
  filter(Code %in% final_items) %>% 
  mutate(Subscale = case_when(grepl("emo", Code) ~ paste("Emotional"),
                              grepl("exp", Code) ~ paste("Experiential"),
                              grepl("mind", Code) ~ paste("Presence"),
                              grepl("spirit", Code) ~ paste("Deep"))) %>% 
  dplyr::select(Subscale, Code, Items) %>% 
  arrange(factor(Subscale, levels = c("Deep", "Experiential", "Emotional", "Presence"))) %>% 
  flextable() %>% 
  width(j = 1, width = 2.5) %>%
  width(j = 2, width = 2.5) %>% 
  width(j = 3, width = 6) %>% 
  autofit() %>% 
  theme_zebra()

ctnflex

```

## Hypothesis 1 - Dimensional Structure

Based on previous multi-dimensional CTN measures and [pilot data using
both exploratory factor analysis and confirmatory factor
analysis](/publication/conference-paper), our first hypothesis is that a
confirmatory factor analysis (CFA) on the DEEP CTN Scale items will
confirm a multidimensional structure with four distinct factors and that
this multi-dimensional structure will be more informative than a single
uni-dimensional structure.

### Hypothesis 1.A - Four-factor Structure

A CFA will confirm a multidimensional structure with four unique factors
defined as:

1.  Deep Identity (deeply seeing the self as part of nature)
2.  Experiential Connection (spending and enjoying time in nature)
3.  Emotional Connection (Emotional desire to connect with nature and
    protect it)
4.  Presence within Nature (engaging mindfully and consciously with
    nature)

Using the Lavaan package in R [@lavaan], we used the Huber-White maximum
likelihood estimation method which is robust to non-normal data. The
number of factors was set to four and covariances allowed between them.

Figure 2 shows the standardized estimates for each item regressed onto
the four factors. All items significantly loaded onto their respective
factors (p \< 0.001). In terms of fit indices, the chi-square, root mean
square error of approximation, standardized root mean square residual,
and the Tucker-Lewis fit index for the four-factor model were acceptable
(see Table 3 for model fit comparisons).

```{r 4 Factor flat, include=FALSE, echo=FALSE}
model_flat_4 <-  'deep =~ 
  CTN_spirit_1 + 
  CTN_spirit_2 +
  CTN_spirit_3 +
  CTN_spirit_4 +
  CTN_spirit_6 +
  CTN_spirit_7 +
  CTN_spirit_8 +
  CTN_spirit_9 +
  CTN_spirit_10

experience =~ 
   CTN_exp_1 +
   CTN_exp_2 +
   CTN_exp_3 +
   CTN_exp_4 +
   CTN_exp_5 +
   CTN_exp_6 +
   CTN_exp_8

emotion =~ 
  CTN_emo_1 +
  CTN_emo_2 +
  CTN_emo_3 +
  CTN_emo_4 +
  CTN_emo_6

presence =~
  CTN_mind_1 +
  CTN_mind_2 +
  CTN_mind_3 +
  CTN_mind_4 +
  CTN_mind_5 +
  CTN_mind_6

deep ~~ experience
deep ~~ emotion
deep ~~ presence
experience ~~ emotion
experience ~~ presence
emotion ~~ presence'

fit_model_flat_4 <- 
  lavaan::cfa(model_flat_4, 
              data = items,
              std.lv = F,
              estimator = "MLR",
              orthogonal = F) 

#Standardized Beta here are the factor loadings
estimates <-
  parameterEstimates(fit_model_flat_4, standardized=TRUE) %>% 
  dplyr::filter(op == "=~") %>% 
  dplyr::select("Latent Variable"=lhs, 
                Indicator=rhs, 
                "b"= est, 
                SE=se,
                Z=z, 
                "p-value"=pvalue, 
                Beta=std.all) %>% 
  flextable() %>% 
  colformat_double(j = 3:7, digits = 2) 


Plot_4_flat <-
     semPaths(fit_model_flat_4, 
         whatLabels = "std",
        layout="tree",
        rotation = 4,
        fade=T,
        curve = 1.5,
        weighted = T, #makes lines bolder for higher numbers
        nCharNodes = 10, #number of text characters to allow in each box
        shapeMan = "rectangle", 
        sizeMan = 35, 
        sizeMan2 = 2,
        border.width = .5,
        label.prop = 0.8,
        asize = 1.5,
        mar = c(.5,5,.5,4),
        residuals=F, #errors? how do I interpret this?
        curvePivot = TRUE, 
        edge.label.cex=.75, #size of numbers
        cardinal = TRUE,
        nodeLabels = c("View nature as a mother", #Deep
                       "Humans and nature connected by same 'Energy'", 
                       "My connection is 'Spiritual'", 
                       "Every part of nature is sacred",
                       "When I die, my body will return to the earth",
                       "'Shared breath' between myself and #plants", 
                       "All life is grounded on this planet", 
                       "Indoor plants are family",
                       "When I eat, I feel thankful for animals and plants",
                       "I like to get outdoors when I can", #experience 
                       "I feel uneasy if away from nature for too long", 
                       "I engage in nature to find meaning & richness",
                       "My favorite is in nature", 
                       "Walking through a forest makes me forget worries",
                       "I prefer outdoor sports",
                       "I hike or run in nearby nature", 
                       "Seeing a cleared forest is upsetting to me",#emotional
                       "If one of my plants died, I would blame myself",
                       "Someone carving a tree makes me cringe",  
                       "I catch and release insects in my home",
                       "I talk to wild animals I encounter",
                       "I take time to watch the clouds pass by", #presence
                       "I deliberately watch the Stars at night", 
                       "I take time to watch the sunrise & sunset", 
                       "I consciously listen to birds", 
                       "I take time to consciously smell flowers", 
                       "I pay attention to phases of the moon",
                       "Deep", 
                       "Experience", 
                       "Emotion", 
                       "Presence")
        )

Fit_table_4factor <- matrix(fitMeasures(fit_model_flat_4, c("df", "chisq", "rmsea", "rmsea.ci.lower", "rmsea.ci.upper", "srmr", "tli", "cfi", "aic")), 
                         ncol=9,
                         byrow=TRUE)
chi_df4 <- paste0(round(Fit_table_4factor[2],2), " (",
                 Fit_table_4factor[1],")")
rmsea_ci4 <- paste0(round(Fit_table_4factor[3],2), " (", 
                  round(Fit_table_4factor[4],2), " - ", 
                  round(Fit_table_4factor[5],2), ")")
srmr4 <- round(Fit_table_4factor[6],2)
tli4 <- round(Fit_table_4factor[7],2)
cfi4 <- round(Fit_table_4factor[8],2)
aic4 <- round(Fit_table_4factor[9],2)

fit_4 <- tibble(chi_df4, rmsea_ci4, srmr4, tli4)
colnames(fit_4) <- c("\u03c7\u00B2 (df)",
                    "RMSEA (95% CI)",
                    "RMSR",
                    "TLI")

#gives me the correlations between factors
cov2cor(inspect(fit_model_flat_4, what = "est")$psi) %>% 
  round(2) %>% 
  as.data.frame() %>% 
  rownames_to_column() %>%
  dplyr::rename(" " = "rowname") %>%
  flextable 





```

**Figure 2. Four-factor dimensional structure with standardized
estimates**

```{r flat 4 factor model plot, echo=FALSE, out.width="100%"}
plot(Plot_4_flat)

```

```{r factor four fit indices, eval=FALSE, include=FALSE}

flextable(fit_4) %>% 
  autofit() %>% 
  flextable::footnote(i = 1, j = 1:4, part = "header",
              value = flextable::as_paragraph(
                c("Chi-Square: Closer to 0 indicate better fit",
                  "Root mean square error: 0.01 = Excellent; 0.05 = Good; 0.08 = Mediocre",
                  "Standardized root mean square residual: Closer to 0 indicate better fit",
                "Tucker Lewis Index: Closer to 1 indicates better fit")),
              ref_symbols = c("a", "b","c", "d"))
```

```{r model 4 mod indices, eval=FALSE, include=FALSE}
#This was looking at better model fit
#may be relevant in exploratory supplementary details
modindices(fit_model_flat_4, sort = T) %>% 
  as.data.frame() %>% 
  arrange(-mi) %>% 
  filter(mi > 11) %>% 
  dplyr::select(lhs, op, rhs, mi, epc)

#moving exp_3 onto deep because of better model fit
model_flat_4_MI <- 'deep =~ 
  CTN_spirit_1 + 
  CTN_spirit_2 +
  CTN_spirit_3 +
  CTN_spirit_4 +
  CTN_spirit_6 +
  CTN_spirit_7 +
  CTN_spirit_8 +
  CTN_spirit_9 +
  CTN_spirit_10 +
  CTN_exp_3      

experience =~ 
   CTN_exp_1 +
   CTN_exp_2 +
   CTN_exp_4 +
   CTN_exp_5 +
   CTN_exp_6 +
   CTN_exp_8

emotion =~ 
  CTN_emo_1 +
  CTN_emo_2 +
  CTN_emo_3 +
  CTN_emo_4 +
  CTN_emo_6

presence =~
  CTN_mind_1 +
  CTN_mind_2 +
  CTN_mind_3 +
  CTN_mind_4 +
  CTN_mind_5 +
  CTN_mind_6

deep ~~ experience
deep ~~ emotion
deep ~~ presence
experience ~~ emotion
experience ~~ presence
emotion ~~ presence'

fit_model_flat_4_MI <- 
  lavaan::cfa(model_flat_4_MI, 
              data = items,
              std.lv = F,
              estimator = "MLR") 

#Standardized Beta here are the factor loadings
estimates <-
  parameterEstimates(fit_model_flat_4_MI, standardized=TRUE) %>% 
  dplyr::filter(op == "=~") %>% 
  dplyr::select("Latent Variable"=lhs, 
                Indicator=rhs, 
                "b"= est, 
                SE=se,
                Z=z, 
                "p-value"=pvalue, 
                Beta=std.all) %>% 
  flextable() %>% 
  colformat_double(j = 3:7, digits = 2) 

Plot_4_flatMI <-
     semPaths(fit_model_flat_4_MI,
         whatLabels = "std",
        layout="tree",
        rotation = 4,
        fade=T,
        curve = 1.5,
        weighted = T, #makes lines bolder for higher numbers
        nCharNodes = 10, #number of text characters to allow in each box
        shapeMan = "rectangle", 
        sizeMan = 35, 
        sizeMan2 = 2,
        border.width = .5,
        label.prop = 0.8,
        asize = 1.5,
        mar = c(.5,5,.5,4),
        residuals=F, #errors? how do I interpret this?
        curvePivot = TRUE, 
        edge.label.cex=.75, #size of numbers
        cardinal = TRUE,
        nodeLabels = c("View nature as a mother", #Deep
                       "Humans and nature connected by same 'Energy'", 
                       "My connection is 'Spiritual'", 
                       "Every part of nature is sacred",
                       "When I die, my body will return to the earth",
                       "'Shared breath' between myself and #plants", 
                       "All life is grounded on this planet", 
                       "Indoor plants are family",
                       "When I eat, I feel thankful for animals and plants",
                       "I engage in nature to find meaning & richness",
                       "I like to get outdoors when I can", #experience 
                       "I feel uneasy if away from nature for too long", 
                       "My favorite is in nature", 
                       "Walking through a forest makes me forget worries",
                       "I prefer outdoor sports",
                       "I hike or run in nearby nature", 
                       "Seeing a cleared forest is upsetting to me",#emotional
                       "If one of my plants died, I would blame myself",
                       "Someone carving a tree makes me cringe",  
                       "I catch and release insects in my home",
                       "I talk to wild animals I encounter",
                       "I take time to watch the clouds pass by", #presence
                       "I deliberately watch the Stars at night", 
                       "I take time to watch the sunrise & sunset", 
                       "I consciously listen to birds", 
                       "I take time to consciously smell flowers", 
                       "I pay attention to phases of the moon",
                       "Deep", 
                       "Experience", 
                       "Emotion", 
                       "Presence")
        )

Fit_table_4factorMI <- matrix(fitMeasures(fit_model_flat_4_MI, c("df", "chisq", "rmsea", "rmsea.ci.lower", "rmsea.ci.upper", "srmr", "tli", "cfi", "aic")), 
                         ncol=9,
                         byrow=TRUE)
chi_df4MI <- paste0(round(Fit_table_4factorMI[2],2), " (",
                 Fit_table_4factorMI[1],")")
rmsea_ci4MI <- paste0(round(Fit_table_4factorMI[3],2), " (", 
                  round(Fit_table_4factorMI[4],2), " - ", 
                  round(Fit_table_4factorMI[5],2), ")")
srmr4MI <- round(Fit_table_4factorMI[6],2)
tli4MI <- round(Fit_table_4factorMI[7],2)
cfi4MI <- round(Fit_table_4factorMI[8],2)
aic4MI <- round(Fit_table_4factorMI[9],2)

fit_4MI <- tibble(chi_df4MI, rmsea_ci4MI, srmr4MI, tli4MI)
colnames(fit_4MI) <- c("\u03c7\u00B2 (df)",
                    "RMSEA (95% CI)",
                    "RMSR",
                    "TLI")

#gives me the correlations between factors
cov2cor(inspect(fit_model_flat_4_MI, what = "est")$psi) %>% 
  round(2) %>% 
  as.data.frame() %>% 
  rownames_to_column() %>%
  dplyr::rename(" " = "rowname") %>%
  flextable 

flextable(fit_4MI) %>% 
  autofit() %>% 
  flextable::footnote(i = 1, j = 1:4, part = "header",
              value = flextable::as_paragraph(
                c("Chi-Square: Closer to 0 indicate better fit",
                  "Root mean square error: 0.01 = Excellent; 0.05 = Good; 0.08 = Mediocre",
                  "Standardized root mean square residual: Closer to 0 indicate better fit",
                "Tucker Lewis Index: Closer to 1 indicates better fit")),
              ref_symbols = c("a", "b","c", "d"))

```

### Hypothesis 1.B - Hierarchical factor Structure

We also hypothesized that all factors would load onto a second-order CTN
factor. This would suggest that the factors themselves are associated
via one overall CTN construct.

Figure 3 shows the standardized estimates for each item regressed onto
the four factors and a second-order CTN factor. All items significantly
loaded onto their respective factors (p \< 0.001). In terms of fit
indices, the chi-square, root mean square error of approximation,
standardized root mean square residual, and the Tucker-Lewis fit index
for the four-factor model were acceptable (Table 3 for model fit
comparisons).

**Figure 3. Four-factor hierarchical dimensional structure with
standardized estimates**

```{r CFA - 4 factor hierarchical, echo=FALSE, include=FALSE}
model_hier_4 <- 'deep =~ 
  CTN_spirit_1 + 
  CTN_spirit_2 +
  CTN_spirit_3 +
  CTN_spirit_4 +
  CTN_spirit_6 +
  CTN_spirit_7 +
  CTN_spirit_8 +
  CTN_spirit_9 +
  CTN_spirit_10
experience =~ 
   CTN_exp_1 +
   CTN_exp_2 +
   CTN_exp_3 +
   CTN_exp_4 +
   CTN_exp_5 +
   CTN_exp_6 +
   CTN_exp_8
emotion =~ 
  CTN_emo_1 +
  CTN_emo_2 +
  CTN_emo_3 +
  CTN_emo_4 +
  CTN_emo_6
presence =~
  CTN_mind_1 +
  CTN_mind_2 +
  CTN_mind_3 +
  CTN_mind_4 +
  CTN_mind_5 +
  CTN_mind_6
  
deepctn =~ deep + experience + emotion + presence'

fit_model_hier_4 <- 
  cfa(model_hier_4, 
      data=items,
      std.lv=F, 
      estimator = "MLR")

#Standardized Beta here are the factor loadings
estimates_heir <-
  parameterEstimates(fit_model_hier_4, standardized=TRUE) %>% 
  dplyr::filter(op == "=~") %>% 
  dplyr::select("Latent Variable"=lhs, 
                Indicator=rhs, 
                "b"= est, 
                SE=se,
                Z=z, 
                "p-value"=pvalue, 
                Beta=std.all) %>% 
  flextable() %>% 
  colformat_double(j = 3:7, digits = 2) 

Plot_heir4 <-
     semPaths(fit_model_hier_4, 
         whatLabels = "std",
        layout="tree",
        style="lisrel",
        rotation = 4,
        weighted = T, #makes lines bolder for higher numbers
        nCharNodes = 10, #number of text characters to allow in each box
        shapeMan = "rectangle", 
        sizeMan = 35, 
        sizeMan2 = 2,
        border.width = .5,
        label.prop = 0.8,
        asize = 1.5,
        mar = c(.5,5,.5,4),
        residuals=F, #errors? how do I interpret this?
        curvePivot = TRUE, 
        edge.label.cex= .75, #size of numbers
        cardinal = TRUE,    
        nodeLabels = c("View nature as a mother", 
                       "Humans and nature connected by same 'Energy'", 
                       "My connection is 'Spiritual'", 
                       "Every part of nature is sacred",
                       "When I die, my body will return to the earth",
                       "'Shared breath' between myself and #plants", 
                       "All life is grounded on this planet", 
                       "Indoor plants are family",
                       "When I eat, I feel thankful for animals and plants",
                       "I like to get outdoors when I can", #experience 
                       "I feel uneasy if away from nature for too long", 
                       "I engage in nature to find meaning & richness",
                       "My favorite is in nature", 
                       "Walking through a forest makes me forget worries",
                       "I prefer outdoor sports",
                       "I hike or run in nearby nature", 
                       "Seeing a cleared forest is upsetting to me",#emotional
                       "If one of my plants died, I would blame myself",
                       "Someone carving a tree makes me cringe", 
                       "I catch and release insects in my home",
                       "I talk to wild animals I encounter",
                       "I take time to watch the clouds pass by", #presence
                       "I deliberately watch the Stars at night", 
                       "I take time to watch the sunrise & sunset", 
                       "I consciously listen to birds", 
                       "I take time to consciously smell flowers", 
                       "I pay attention to phases of the moon",
                       "Deep", 
                       "Experience", 
                        "Emotion", 
                       "Presence",
                       "Overall CTN")
        )
                      

Fit_table_heir <- matrix(fitMeasures(fit_model_hier_4, c("df", "chisq", "rmsea", "rmsea.ci.lower", "rmsea.ci.upper", "srmr", "tli", "cfi", "aic")), 
                         ncol=9,
                         byrow=TRUE)
chi_df4h <- paste0(round(Fit_table_heir[2],2), " (",
                 Fit_table_heir[1],")")
rmsea_ci4h <- paste0(round(Fit_table_heir[3],2), " (", 
                  round(Fit_table_heir[4],2), " - ", 
                  round(Fit_table_heir[5],2), ")")
srmr4h <- round(Fit_table_heir[6],2)
tli4h <- round(Fit_table_heir[7],2)
cfi4h <- round(Fit_table_heir[8],2)
aic4h <- round(Fit_table_heir[9],2)

fit_4h <- tibble(chi_df4h, rmsea_ci4h, srmr4h, tli4h)
colnames(fit_4h) <- c("\u03c7\u00B2 (df)",
                    "RMSEA (95% CI)",
                    "RMSR",
                    "TLI")

#gives me the correlations between factors
model_4_hier_cors <-
inspect(fit_model_hier_4, what="cor.lv") %>% 
  as.data.frame() %>% 
  round(2) %>% 
  dplyr::select(-deepctn) %>% 
  rownames_to_column() %>% 
  filter(rowname != "deepctn")


```

```{r 4-factor hierarchical plot, include=TRUE, echo=FALSE, out.width="100%"}
plot(Plot_heir4)


```

```{r heirarchial fit indices, eval=FALSE, include=FALSE}

flextable(fit_4h) %>% 
  autofit() %>% 
  flextable::footnote(i = 1, j = 1:4, part = "header",
              value = flextable::as_paragraph(
                c("Chi-Square: Closer to 0 indicate better fit",
                  "Root mean square error: 0.01 = Excellent; 0.05 = Good; 0.08 = Mediocre",
                  "Standardized root mean square residual: Closer to 0 indicate better fit",
                "Tucker Lewis Index: Closer to 1 indicates better fit")),
              ref_symbols = c("a", "b","c", "d"))
     

```

### Hypothesis 1.C - Single Factor Model

We further predicted that both of the above models (1. four factor model
and 2. four factor hierarchical model) will provide better explanatory
fit than a unidimensional factor containing only a total CTN score.

Figure 4 shows the standardized estimates for each item regressed onto a
single overarching CTN factor. While al items significantly loaded onto
their respective factors (p \< 0.001), the fit indices suggest that this
model has poor fit (see Table 3 for model fit comparisons).

**Figure 4. Unidimensional factor structure with standardized
estimates**

```{r CFA - 1 factor, include=FALSE, echo=FALSE}

model_flat <-  'overall =~ 
  CTN_spirit_1 + 
  CTN_spirit_2 +
  CTN_spirit_3 +
  CTN_spirit_4 +
  CTN_spirit_6 +
  CTN_spirit_7 +
  CTN_spirit_8 +
  CTN_spirit_9 +
  CTN_spirit_10 +

   CTN_exp_1 +
   CTN_exp_2 +
   CTN_exp_3 +
   CTN_exp_4 +
   CTN_exp_5 +
   CTN_exp_6 +
   CTN_exp_8 +

  CTN_emo_1 +
  CTN_emo_2 +
  CTN_emo_3 +
  CTN_emo_4 +
  CTN_emo_6 +

  CTN_mind_1 +
  CTN_mind_2 +
  CTN_mind_3 +
  CTN_mind_4 +
  CTN_mind_5 +
  CTN_mind_6'

fit_model_flat <- 
  cfa(model_flat, 
      data=items,
      std.lv=F, 
      estimator = "MLR") 

#Standardized Beta here are the factor loadings
estimates_flat <-
  parameterEstimates(fit_model_flat, standardized=TRUE) %>% 
  dplyr::filter(op == "=~") %>% 
  dplyr::select("Latent Variable"=lhs, 
                Indicator=rhs, 
                "b"= est, 
                SE=se,
                Z=z, 
                "p-value"=pvalue, 
                Beta=std.all) %>% 
  flextable() %>% 
  colformat_double(j = 3:7, digits = 2) 

Plot_1_flat <-
     semPaths(fit_model_flat, 
         whatLabels = "std", #"par" = unstandardized loading, "std" = standardized. In graphs std is more common. Here the top variable error variance goes to 1 because everything is standardized on that latent variable. This also standarizes all the errors which makes them SD's
        layout="tree",
        rotation = 4,
        weighted = T, #makes lines bolder for higher numbers
        nCharNodes = 10, #number of text characters to allow in each box
        shapeMan = "rectangle", 
        sizeMan = 35, 
        sizeMan2 = 2,
        border.width = .5,
        label.prop = 0.8,
        asize = 1.5,
        mar = c(.5,5,.5,4),
        residuals=F, 
        curvePivot = TRUE, 
        edge.label.cex=.75, #size of numbers
        cardinal = TRUE,
        nodeLabels = c("View nature as a mother", #Deep
                       "Humans and nature connected by same #'Energy'", 
                       "My connection is 'Spiritual'", 
                       "Every part of nature is sacred",
                       "When I die, my body will return to the earth",
                       "'Shared breath' between myself and #plants", 
                       "All life is grounded on this planet", 
                       "Indoor plants are family",
                       "When I eat, I feel thankful for animals and plants",
                       "I like to get outdoors when I can", #experience 
                       "I feel uneasy if away from nature for too long", 
                       "I engage in nature to find meaning & richness",
                       "My favorite is in nature", 
                       "Walking through a forest makes me forget worries",
                       "I prefer outdoor sports",
                       "I hike or run in nearby nature", 
                       "Seeing a cleared forest is upsetting to me",#emotional
                       "If one of my plants died, I would blame myself",
                       "Someone carving a tree makes me cringe",
                       "I catch and release insects in my home",
                       "I talk to wild animals I encounter",
                       "I take time to watch the clouds pass by", #presence
                       "I deliberately watch the Stars at night", 
                       "I take time to watch the sunrise & sunset", 
                       "I consciously listen to birds", 
                       "I take time to consciously smell flowers", 
                       "I pay attention to phases of the moon",
                      "CTN Overall"))


Fit_table_flat <- 
  matrix(fitMeasures(fit_model_flat, c("df", "chisq", "rmsea", "rmsea.ci.lower", "rmsea.ci.upper", "srmr", "tli", "cfi", "aic")), 
                         ncol=9,
                         byrow=TRUE)
chi_dff <- paste0(round(Fit_table_flat[2],2), " (",
                 Fit_table_flat[1],")")
rmsea_cif <- paste0(round(Fit_table_flat[3],2), " (", 
                  round(Fit_table_flat[4],2), " - ", 
                  round(Fit_table_flat[5],2), ")")
srmrf <- round(Fit_table_flat[6],2)
tlif <- round(Fit_table_flat[7],2)
cfif <- round(Fit_table_flat[8],2)
aicf <- round(Fit_table_flat[9],2)

fit_flat <- tibble(chi_dff, rmsea_cif, srmrf, tlif)
colnames(fit_flat) <- c("\u03c7\u00B2 (df)",
                    "RMSEA (95% CI)",
                    "RMSR",
                    "TLI")


```

```{r single factor plot, echo=FALSE, out.width="100%"}
plot(Plot_1_flat)
```

```{r fit measures, echo=FALSE}
Fit_table <- matrix(c(
                  fitmeasures(fit_model_flat, "df"),
                  fitmeasures(fit_model_flat, "chisq"),
                  fitmeasures(fit_model_flat, "rmsea"),
                  fitmeasures(fit_model_flat, "rmsea.ci.lower"),
                  fitmeasures(fit_model_flat, "rmsea.ci.upper"),
                  fitmeasures(fit_model_flat, "srmr"),
                  fitmeasures(fit_model_flat, "tli"),
                  fitmeasures(fit_model_flat, "cfi"),
                  fitmeasures(fit_model_flat, "aic"),
                  
                  fitmeasures(fit_model_flat_4, "df"),
                  fitmeasures(fit_model_flat_4, "chisq"),
                  fitmeasures(fit_model_flat_4, "rmsea"),
                  fitmeasures(fit_model_flat_4, "rmsea.ci.lower"),
                  fitmeasures(fit_model_flat_4, "rmsea.ci.upper"),
                  fitmeasures(fit_model_flat_4, "srmr"),
                  fitmeasures(fit_model_flat_4, "tli"),
                  fitmeasures(fit_model_flat_4, "cfi"),
                  fitmeasures(fit_model_flat_4, "aic"),
                  
                  fitmeasures(fit_model_hier_4, "df"),
                  fitmeasures(fit_model_hier_4, "chisq"),
                  fitmeasures(fit_model_hier_4, "rmsea"),
                  fitmeasures(fit_model_hier_4, "rmsea.ci.lower"),
                  fitmeasures(fit_model_hier_4, "rmsea.ci.upper"),
                  fitmeasures(fit_model_hier_4, "srmr"),
                  fitmeasures(fit_model_hier_4, "tli"),
                  fitmeasures(fit_model_hier_4, "cfi"),
                  fitmeasures(fit_model_hier_4, "aic")
                  ), 
                    ncol=9,byrow=TRUE)

#df4, chi-sq3, RMSEA32, RMSEACIUp, RMSEACILow, SRMR28, TFI10, CFI9, AIC 
colnames(Fit_table) <- c("df", "Chi-Sq", "RMSEA","RMSEA CI Lower", "RMSEA CI Upper", "RMSR", "TLI", "CFI", "AIC")
rownames(Fit_table) <- c("1-Factor",
                         "4-Factor", "4-Factor Hierarchial")


```


## Shortened DEEP CTN Scale

In order to produce a scale that is not only psychometrically sound, but
also practical for use in future research, we conducted a reduced CFA.
We retained the five strongest loading items from each factor to create
the reduced scale. However, only three items remained in the emotional
dimension due to high skew. This resulted in a measure with 18 items.

Figure 5 shows the standardized estimates for each item regressed onto
the four factors and a second-order CTN factor. All items significantly
loaded onto their respective factors (p \< 0.001). In terms of fit
indices, the chi-square, root mean square error of approximation,
standardized root mean square residual, and the Tucker-Lewis fit index
for the four-factor model were acceptable (see Table 3 for model fit comparisons).

```{r reduced CFA, include=FALSE}
#based on the strongest loading items
reduced <- 
  items %>% 
  dplyr::select(CTN_spirit_2,
                CTN_spirit_3,
                CTN_spirit_7,
                CTN_spirit_1,
                CTN_spirit_4,

                CTN_exp_4,
                CTN_exp_1,
                CTN_exp_3,
                CTN_exp_2,
                CTN_exp_5,
         
                CTN_emo_3,
                CTN_emo_4,
                CTN_emo_6,
                CTN_emo_1,
                CTN_emo_2,
                
                CTN_mind_2,
                CTN_mind_1,
                CTN_mind_3,
                CTN_mind_5,
                CTN_mind_4)


deep_alpha <- 
reduced %>% 
  dplyr::select(CTN_spirit_2,
                CTN_spirit_3,
                CTN_spirit_7,
                CTN_spirit_1,
                CTN_spirit_4) %>% 
ltm::cronbach.alpha()

exp_alpha <- 
reduced %>% 
  dplyr::select(CTN_exp_4,
                CTN_exp_1,
                CTN_exp_3,
                CTN_exp_2,
                CTN_exp_5) %>% 
ltm::cronbach.alpha()

emo_alpha <- 
reduced %>% 
  dplyr::select(CTN_emo_3,
                CTN_emo_4,
                CTN_emo_6,
                CTN_emo_2,
                CTN_emo_1) %>% 
ltm::cronbach.alpha()

presc_alpha <- 
reduced %>% 
  dplyr::select(CTN_mind_2,
                CTN_mind_1,
                CTN_mind_3,
                CTN_mind_5,
                CTN_mind_4) %>% 
ltm::cronbach.alpha()

alpha_reduced <-  
  tibble("Deep" = c(deep_alpha$alpha, 5),
         "Experience" = c(exp_alpha$alpha, 5),
         "Emotion" = c(emo_alpha$alpha, 3),
         "Presence" = c(presc_alpha$alpha, 5)) %>% 
    round(2) %>% 
  rownames_to_column() %>% 
    mutate(rowname = case_when(
      rowname == "1" ~ "Cronbach's Alpha",
      rowname == "2" ~ "Number of Items"
    )) %>% 
    flextable() %>% 
  colformat_double(i=2, j = 2:5, digits = 0) %>% 
    set_header_labels(rowname = " ", Deep = "Deep",
                      Experience = "Experience", Emotion = "Emotion",
                      Presence = "Presence") %>% 
    autofit() %>% 
    footnote(i = 1, j = 1, part = "body",
              value = flextable::as_paragraph(
                c(">= 0.9: Excellent \n
                  0.8 - 0.9: Good \n
                  0.7 - 0.8: Acceptable \n
                  0.6 - 0.7: Questionable \n
                 0.5 - 0.6: Poor \n
                 < 0.5: Unacceptable")),
              ref_symbols = c("a"))

```

```{r CFA - reduced 4 factor hier, echo=FALSE, include=FALSE}
reduced_hier_4 <-
'deep =~ 
  CTN_spirit_2 +
  CTN_spirit_3 +
  CTN_spirit_7 +
  CTN_spirit_1 +
  CTN_spirit_4
experience =~ 
   CTN_exp_4 +
   CTN_exp_1 +
   CTN_exp_3 +
   CTN_exp_2 +
   CTN_exp_5
emotion =~ 
  CTN_emo_3 +
  CTN_emo_4 +
  CTN_emo_6 +
  CTN_emo_1 +
  CTN_emo_2 
presence =~
  CTN_mind_2 +         
  CTN_mind_1 +
  CTN_mind_3 +
  CTN_mind_5 +
  CTN_mind_4
deepctn =~ deep + experience + emotion + presence'

fit_reduced_hier_4 <- cfa(reduced_hier_4, data=reduced,
                        std.lv=F, 
                        estimator = "MLR",
                        orthogonal = F) 

#Standardized Beta here are the factor loadings
estimates_red <-
  parameterEstimates(fit_reduced_hier_4, standardized=TRUE) %>% 
  dplyr::filter(op == "=~") %>% 
  dplyr::select("Latent Variable"=lhs, 
                Indicator=rhs, 
                "b"= est, 
                SE=se,
                Z=z, 
                "p-value"=pvalue, 
                Beta=std.all) %>% 
  flextable() %>% 
  colformat_double(j = 3:7, digits = 2) 
Plot_reduced <-
     semPaths(fit_reduced_hier_4, 
         whatLabels = "std", 
        layout="tree",
        rotation = 4,
        weighted = T, #makes lines bolder for higher numbers
        nCharNodes = 10, #number of text characters to allow in each box
        shapeMan = "rectangle", 
        sizeMan = 35, 
        sizeMan2 = 2,
        border.width = .5,
        label.prop = 0.8,
        asize = 1.5,
        mar = c(.5,5,.5,4),
        residuals=F, #errors? how do I interpret this?
        curvePivot = TRUE, 
        edge.label.cex= .75, #size of numbers
        cardinal = TRUE,
        nodeLabels = c("Humans and nature connected by same 'Energy'", #Deep
                       "My connection is 'Spiritual'",
                       "'Shared breath' between myself and plants", 
                       "View nature as a mother", 
                       "Every part of nature is sacred", 
                       "My favorite is in nature",#experience 
                       "I like to get outdoors when I can", 
                       "I engage in nature to find meaning & richness",
                       "I feel uneasy if away from nature for too long",
                       "Walking through a forest makes me forget worries",
                       "Someone carving a tree makes me cringe",  #emotional
                       "I catch and release insects in my home",
                       "I talk to wild animals I encounter",
                       "Seeing a cleared forest is upsetting",
                       "If one of my plants died I would be upset",
                       "I deliberately watch the stars at night", #presence
                       "I take time to watch the clouds pass by",
                       "Watch sunrish and sunset",
                       "I consciously listen to birds",
                       "I take time to consciously smell flowers",
                       "Deep", 
                       "Experience", 
                       "Emotion", 
                       "Presence",
                       "Overall CTN")
        )

Fit_table_red <- matrix(fitMeasures(fit_reduced_hier_4, c("df.scaled", "chisq.scaled", "rmsea.robust", "rmsea.ci.lower.robust", "rmsea.ci.upper.robust", "srmr", "tli.robust", "cfi.robust", "aic")), 
                         ncol=9,
                         byrow=TRUE)
chi_dfr <- paste0(round(Fit_table_red[2],2), " (",
                 Fit_table_red[1],")")
rmsea_cir <- paste0(round(Fit_table_red[3],2), " (", 
                  round(Fit_table_red[4],2), " - ", 
                  round(Fit_table_red[5],2), ")")
srmrr <- round(Fit_table_red[6],2)
tlir <- round(Fit_table_red[7],2)
cfir <- round(Fit_table_red[8],2)
aicr <- round(Fit_table_red[9],2)

fit_red <- tibble(chi_dfr, rmsea_cir, srmrr, tlir, cfir, aicr)
colnames(fit_red) <- c("\u03c7\u00B2 (df)",
                    "RMSEA (95% CI)",
                    "RMSR",
                    "TLI",
                    "CFI",
                    "AIC")
fit_red <-
fit_red %>% 
  mutate(Model = "Reduced") %>% 
  dplyr::select(Model, everything())


```

**Figure 5. Reduced DEEP CTN Scale factor structure with standardized
estimates**

```{r 4 factor reduced hierarchical plot, include=TRUE, echo=FALSE, out.width="100%"}
plot(Plot_reduced)

```

**Table 3. Comparative Fit indices for each model**

```{r Fit table, echo=FALSE}

Fit_table <-
Fit_table %>% 
  round(2) %>% 
  as.data.frame() %>% 
  rownames_to_column() %>% 
  dplyr::mutate(df = paste(`Chi-Sq`, " (", df, ")"),
         RMSEA = paste(RMSEA, " (", `RMSEA CI Lower`, " - ", `RMSEA CI Upper`, ")")) %>% 
  dplyr::select(rowname, df, RMSEA, RMSR, TLI, CFI, AIC) 

colnames(Fit_table) <- c("Model", 
                         "\u03c7\u00B2 (df)",
                         "RMSEA (95% CI)",
                         "RMSR",
                         "TLI", "CFI", "AIC") 
  
Fit_table <- 
  Fit_table %>% 
  as_tibble() %>% 
  bind_rows(fit_red)
  

flextable(Fit_table) %>% 
  bold(i = 4,
       part = "body") %>% 
  autofit() %>% 
  flextable::footnote(i = 1, j = 2:7, part = "header",
              value = flextable::as_paragraph(
                c("Chi-Square: Closer to 0 indicate better fit",
                  "Root mean square error: 0.01 = Excellent; 0.05 = Good; 0.08 = Mediocre",
                  "Standardized root mean square residual: Closer to 0 indicate better fit",
                "Tucker Lewis Index: Closer to 1 indicates better fit",
                "Comparative fit index: Closer to 1 indicates better fit",
                "Akaike’s Information Criterion: The lower the AIC, the more predictive")),
              ref_symbols = c("a", "b","c", "d", "e", "f"))
     
```

```{r Model Comparisons, include=FALSE}
test_all<-
  lavaan::anova(fit_model_flat,
      fit_model_flat_4,
      fit_model_hier_4,
      fit_reduced_hier_4)

x2_1 <- round(test_all$Chisq[2],3)
df_1 <- test_all$Df[2]
p_1 <- papaja::print_p(round(test_all$`Pr(>Chisq)`[2],3))
  
x2_2 <- round(test_all$Chisq[3],3)
df_2 <- test_all$Df[3]
p_2<- papaja::print_p(round(test_all$`Pr(>Chisq)`[3],3))

x2_3 <- round(test_all$Chisq[4],3)
df_3 <- test_all$Df[4]
p_3<- papaja::print_p(round(test_all$`Pr(>Chisq)`[4],3))


```

An Analysis of Variance comparing the model fit of the four factor
structures showed that there was 
1. no significant difference between the
two multi-dimensional models (Chi-sq= `r x2_1`(`r df_1`), p = `r p_1`).

2. the multi-dimensional models had significantly improved fit
compared to the unidimensional model (Chi-sq = `r x2_2`(`r df_2`), p =
`r p_2`).

3. the reduced scale (20 items) further significantly improved the fit compared to the longer scale which included all items (Chi-sq = `r x2_3`(`r df_3`), p = `r p_3`).





We also expected weak-to-moderate zero-order correlations between the
four Deep CTN factors as they are predicted to be associated via one CTN
construct (as would be supported by the hierarchical factor mentioned
above). This was tested using a Zero-Order Correlation between the four
factors. Figure 6. shows the inter-correlations between the factors
revealing moderate relationships between all factors.

```{r creating the scale, echo=FALSE}
#select necessary items
val_data <-
  data %>% 
  dplyr::select(id, definition,
         CTN_spirit_1, CTN_spirit_2, CTN_spirit_3, CTN_spirit_7,CTN_spirit_4,
         CTN_exp_1, CTN_exp_2, CTN_exp_3, CTN_exp_4, CTN_exp_5,
         CTN_emo_1, CTN_emo_2, CTN_emo_3, CTN_emo_4, CTN_emo_6,
         CTN_mind_1, CTN_mind_2, CTN_mind_4, CTN_mind_5, CTN_mind_6,
         
         EIDR_1, EIDR_2, EIDR_3, EIDR_4, EIDR_5, EIDR_6, EIDR_7, 
         EIDR_8, EIDR_9, EIDR_10, EIDR_11, EIDR_12, EIDR_13, EIDR_14,
         
         CNS_1, CNS_2, CNS_3, CNS_4, CNS_5, CNS_6, CNS_7,
         CNS_8, CNS_9, CNS_10, CNS_11, CNS_12, CNS_13, CNS_14,
         
         RPEBS_1, RPEBS_2, RPEBS_3, RPEBS_4, RPEBS_5, RPEBS_6, RPEBS_7, 
         RPEBS_8, RPEBS_9, RPEBS_10, RPEBS_11, RPEBS_12, RPEBS_13, RPEBS_14,
         RPEBS_15, RPEBS_16, RPEBS_17, RPEBS_18, RPEBS_19, RPEBS_20,
         
         PI_interconnect_1, PI_interconnect_2, 
         PI_interconnect_3, PI_interconnect_4,
         
         RYFF_1_autonomy, RYFF_2_autonomy, RYFF_3_autonomy, 
         RYFF_4_enviromastery, RYFF_5_enviromastery, RYFF_6_enviromastery,
         RYFF_7_growth, RYFF_8_growth, RYFF_9_growth, 
         RYFF_10_relations, RYFF_11_relations, RYFF_12_relations,
         RYFF_13_purpose, RYFF_14_purpose, RYFF_15_purpose, 
         RYFF_16_selfaccept, RYFF_17_selfaccept, RYFF_18_selfaccept, 
         
         PANAS_1, PANAS_2, PANAS_3, PANAS_4, PANAS_5, 
         PANAS_6, PANAS_7, PANAS_8, PANAS_9, PANAS_10,
         
         VITALITY_1, VITALITY_2, VITALITY_3, 
         VITALITY_4, VITALITY_5, VITALITY_6,
         
         SES_peers,
         politics_overall, politics_economic, politics_social,
         age, gender, gender_dummy, race) %>% 
  mutate(across(3:112, as.numeric))
```


```{r four factor correlation calcs, echo=FALSE, message=FALSE, warning=FALSE}

fac_cor <-
  val_data %>% 
  mutate(Deep = (CTN_spirit_1 + CTN_spirit_2 + CTN_spirit_3 + CTN_spirit_7 + CTN_spirit_4)/5,
         Experience = (CTN_exp_1+ CTN_exp_2+ CTN_exp_3+ CTN_exp_4+ CTN_exp_5)/5,
         Emotional = (CTN_emo_1 + CTN_emo_2 + CTN_emo_3+ CTN_emo_4+ CTN_emo_6)/3,
         Presence = (CTN_mind_1+ CTN_mind_2+ CTN_mind_4+ CTN_mind_5+ CTN_mind_6)/5) %>%
    dplyr::select(Deep, Experience, Emotional, Presence) %>%
  as.matrix %>% 
  rcorr(type = "spearman")
fac_row = rownames(fac_cor$r)
fac_m = t(combn(fac_row, 2))
fac_d = cbind(data.frame(fac_m), R = fac_cor$r[fac_m], P = fac_cor$P[fac_m])
fac_d$label = round(fac_d$R, 2)
fac_d$label[fac_d$P < 0.001] = paste0(fac_d$label[fac_d$P < 0.001], "\n***")
fac_d$X1 = factor(fac_d$X1, fac_row)
fac_d$X2 = factor(fac_d$X2, rev(fac_row))
graphics.off()
#set colours in scale_fill_manual to be one colour for |0.7| ≤ r (strong correlation), another for |0.4| ≤ r < |0.7| (moderate correlation and another for|0.1| ≤ r < |0.3| (weak correlation)
fac_plot <- 
  fac_d %>% 
  ggplot(aes(X1, X2, fill = R, label = label)) +
    geom_tile(color = "white") +
    scale_fill_viridis_c(begin = 0, end = 1, option = "d", 
                         values = c(0, 0.1, 0.3, 0.4, 0.7, 1)) +
    geom_text(color = ifelse(fac_d$R > 0.6, "black", "white")) +
    theme_bw() +
    coord_equal() +
     theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(caption = "|0.1| ≤ r < |0.3| Weak \n|0.4| ≤ r < |0.7| Moderate \n|0.7| ≤ r Strong \n*** p < 0.001") +
  theme(plot.caption=element_text(hjust = 0))



```

**Figure 6. Correlations between factors in the DEEP CTN Scale**

```{r four factor cor plot, echo=FALSE}
fac_plot
```

# Validation

{{% callout note %}} Validation was completed using the reduced scale of
20 items as it has adequate fit {{% /callout %}}

## Final DEEP CTN Scale

Table 4 shows the Cronbach's alpha for the reduced scale, which was
acceptable for Deep, Experiential, and Presence, but showed a poor fit
for the Emotional dimension.

```{r DEEPCTN Scale, include=FALSE}
#create a table that shows the final items for the DEEP CTN scale

#col names from reduced
codes <- colnames(reduced)
scale <- matrix(c("I view nature as a mother who nurtures and cares for me", "Deep",
    "Human beings and nature are connected by the same energy or Life-force", "Deep",
    "My connection to nature is something I would describe as *spiritual*", "Deep",
    "I think about the *shared breath* between myself and plants; I breathe in the oxygen released by plants, and plants use the carbon dioxide I exhale", "Deep",
    "Every part of nature is sacred","Deep",
    
    
    "I like to get outdoors whenever I get the chance", "Experience",
     "I feel uneasy if I am away from nature for too long","Experience",
     "I engage and participate with nature to find meaning and richness in life","Experience",
    "My favorite place is in nature", "Experience",
    "Walking through a forest makes me forget about my daily worries", "Experience",
     
    
    "Thinking of someone carving their initials into a tree makes me cringe","Emotional",
    "If there is an insect, such as a fly or a spider, in my home, I try to catch and release it rather than kill it", "Emotional",
    "I talk to the wild animals I encounter (e.g., birds, lizards, rabbits, squirrels)",  "Emotional",
    "Seeing a cleared forest is upsetting to me", "Emotional",
    "If one of my plants died, I would be upset", "Emotional",
    
    "I take time to watch the clouds pass by", "Presence",
    "I deliberately take time to watch stars at night", "Presence",
    "I consciously watch or listen to birds", "Presence",
    "I take time to consciously smell flowers", "Presence",
    "I pay attention to the current phase of the moon", "Presence"),
  ncol=2, 
  byrow=TRUE) %>% 
  as.data.frame() 
colnames(scale) <- c("Item", "Scale")

#Cronbach's Alpha for each sub-scale
alpha_deep <- ltm::cronbach.alpha(reduced[,1:5])
alpha_deep <- round(alpha_deep$alpha,2)
alpha_exp <- ltm::cronbach.alpha(reduced[,6:10])
alpha_exp <- round(alpha_exp$alpha,2)
alpha_emo <- ltm::cronbach.alpha(reduced[,11:15])
alpha_emo <- round(alpha_emo$alpha,2)
alpha_pres <- ltm::cronbach.alpha(reduced[,16:20])
alpha_pres <- round(alpha_pres$alpha,2)

scale <- 
scale %>% 
  mutate(Alpha = case_when(Scale == "Deep" ~ alpha_deep,
                           Scale == "Experience" ~ alpha_exp,
                           Scale == "Emotional" ~ alpha_emo,
                           Scale == "Presence" ~ alpha_pres)) %>% 
  as.data.frame()

#Deep table
deep <- 
scale %>% 
filter(Scale == "Deep") %>% 
  dplyr::select(Item) %>% 
  flextable() %>% 
  autofit() %>% 
  set_header_labels(Item ="Deep CTN Subscale") %>% 
  add_footer_row(values = as_paragraph("Cronbach's Alpha: ", alpha_deep),
                 colwidths = 1) 

#Experiential table
experience <- 
scale %>% 
filter(Scale == "Experience") %>% 
  dplyr::select(Item) %>% 
  flextable() %>% 
  autofit() %>% 
  set_header_labels(Item ="Experiential CTN Subscale") %>% 
  add_footer_row(values = as_paragraph("Cronbach's Alpha: ", alpha_exp),
                 colwidths = 1) 

#Emotional table
emotional <- 
scale %>% 
filter(Scale == "Emotional") %>% 
  dplyr::select(Item) %>% 
  flextable() %>% 
  autofit() %>% 
  set_header_labels(Item ="Emotional CTN Subscale") %>% 
  add_footer_row(values = as_paragraph("Cronbach's Alpha: ", alpha_emo),
                 colwidths = 1)

#Presence table
presence <- 
scale %>% 
filter(Scale == "Presence") %>% 
  dplyr::select(Item) %>% 
  flextable() %>% 
  autofit() %>% 
  set_header_labels(Item ="Presence CTN Subscale") %>% 
  add_footer_row(values = as_paragraph("Cronbach's Alpha: ", alpha_pres),
                 colwidths = 1) 

summary_table <- 
  flextable(scale) %>% 
  set_header_labels(Scale = "CTN Subscale", Alpha = "Cronbach's Alpha") %>% 
  valign(valign = "top") %>% 
  autofit() %>%
  merge_v(j = 2:3) %>% 
    theme_booktabs() %>% 
  hline(i = c(5, 10, 15))



```

**Table 4. DEEP CTN Scale including the Cronbach's Alpha for each
factor**

```{r DEEP CTN scale printed, echo=FALSE}
summary_table 
```

```{r convergent validity, message=FALSE, warning=FALSE, include=FALSE}

#reverse score items: CNS_4, CNS_14, REBS_4, REBS_6, REBS_7, REBS_14, PI_interconnect_2, RYFF_1_autonomy, RYFF_4_enviromastery, RYFF_9_growth, RYFF_10_relations, RYFF_12_relations, RYFF_14_purpose, RYFF_15_purpose, RYFF_18_selfaccept

reverse_code <- function(data, columns_to_reverse) {
  data[, columns_to_reverse] <- max(data[, columns_to_reverse]) - data[, columns_to_reverse] + min(data[, columns_to_reverse])
  data
}

reverse_code(val_data, c("CNS_4", "CNS_14", "RPEBS_4", "RPEBS_6", "RPEBS_7", "RPEBS_14", "PI_interconnect_2", "RYFF_1_autonomy", "RYFF_4_enviromastery", "RYFF_9_growth", "RYFF_10_relations", "RYFF_12_relations", "RYFF_14_purpose", "RYFF_15_purpose", "RYFF_18_selfaccept"))

#create scales & standardize
val_data <-
  val_data %>% 
  mutate(DeepCTN = (rowSums(dplyr::select(., CTN_spirit_1:CTN_spirit_4))),
         DeepCTN_z = (DeepCTN - mean(DeepCTN))/sd(DeepCTN),
         ExpCTN = (rowSums(dplyr::select(., CTN_exp_1:CTN_exp_5))),
         ExpCTN_z = (ExpCTN - mean(ExpCTN))/sd(ExpCTN),
         EmoCTN = (rowSums(dplyr::select(., CTN_emo_1:CTN_emo_6))),
         EmoCTN_z = (EmoCTN - mean(EmoCTN))/sd(EmoCTN),
         PresCTN = (rowSums(dplyr::select(., CTN_mind_1:CTN_mind_6))),
         PresCTN_z = (PresCTN - mean(PresCTN))/sd(PresCTN),
         CTN_overall = DeepCTN + ExpCTN + EmoCTN + PresCTN,
         CTN_z = (CTN_overall - mean(CTN_overall))/sd(CTN_overall),
         EIDR = (rowSums(dplyr::select(., EIDR_1:EIDR_14))),
         EIDR_z = (EIDR - mean(EIDR))/sd(EIDR),
         CNS = (rowSums(dplyr::select(., CNS_1:CNS_14))),
         CNS_z = (CNS - mean(CNS))/sd(CNS),
         RPEBS = (rowSums(dplyr::select(., RPEBS_1:RPEBS_20))),
         RPEBS_z = (RPEBS - mean(RPEBS))/sd(RPEBS),
         PI_interconnect = 
           (rowSums(dplyr::select(., PI_interconnect_1:PI_interconnect_4))),
         PI_interconnect_z = 
           (PI_interconnect - mean(PI_interconnect))/sd(PI_interconnect),
         RYFF_autonomy = (rowSums(dplyr::select(., RYFF_1_autonomy:RYFF_3_autonomy))),
         RYFF_enviromastery = 
           (rowSums(dplyr::select(., RYFF_4_enviromastery:RYFF_6_enviromastery))),
         RYFF_growth = (rowSums(dplyr::select(., RYFF_7_growth:RYFF_9_growth))),
         RYFF_relations = 
           (rowSums(dplyr::select(., RYFF_10_relations:RYFF_12_relations))),
         RYFF_purpose = 
           (rowSums(dplyr::select(., RYFF_13_purpose:RYFF_15_purpose))),
         RYFF_selfaccept = 
           (rowSums(dplyr::select(., RYFF_16_selfaccept:RYFF_18_selfaccept))),
         RYFF_overall = RYFF_autonomy + RYFF_enviromastery + RYFF_growth + RYFF_relations + RYFF_purpose + RYFF_selfaccept,
         RYFF_z = (RYFF_overall - mean(RYFF_overall))/sd(RYFF_overall),
         PANAS = (rowSums(dplyr::select(., PANAS_1:PANAS_10))),
         PANAS_z = (PANAS - mean(PANAS))/sd(PANAS),
         VITALITY = (rowSums(dplyr::select(., VITALITY_1:VITALITY_6))),
         Vitality_z = (VITALITY - mean(VITALITY))/sd(VITALITY),
         WB = (RYFF_z + PANAS_z + Vitality_z)/3,
         politics = (politics_overall + politics_economic + politics_social)/3,
         pol_z = (politics - mean(politics))/sd(politics),
         ses_z = (SES_peers - mean(SES_peers))/sd(SES_peers))




#chronbacs alpha on cns and eidr
cns_alpha <- 
  ltm::cronbach.alpha(val_data[,c("CNS_1", "CNS_2", "CNS_3", "CNS_4", "CNS_5", "CNS_6", "CNS_7", "CNS_8", "CNS_9", "CNS_10", "CNS_11", "CNS_12", "CNS_13", "CNS_14")])

eidr_alpha <-
  ltm::cronbach.alpha(val_data[,c("EIDR_1", "EIDR_2", "EIDR_3", "EIDR_4", "EIDR_5", "EIDR_6", "EIDR_7", "EIDR_8", "EIDR_9", "EIDR_10", "EIDR_11", "EIDR_12", "EIDR_13", "EIDR_14")])

#save csv
#write.csv(val_data, "val_data.csv")

```

## Hypothesis 2 - Convergent Validity

Our second hypothesis was that the Deep CTN scale would have convergent
validity, which assesses how closely our new measure is related to other
established measures of the same construct. We tested this by examining
the correlations between two existing measures of CTN:

The Connectedness to Nature Scale (CNS - Mayer & Franz, 2004)
(cronbach's alpha = `r round(cns_alpha$alpha,2)`)

Environmental Identity Scale revised (EID-R - Clayton et al.,
2021)(cronbach's alpha = `r round(eidr_alpha$alpha,2)`).

```{r cormatrix, include=FALSE, fig.id=TRUE}
#| fig.cap = "Spearman correlations between DEEP CTN facets and existing measures of CTN"

cor_cols = c('CTN_z',
             'DeepCTN_z',
             'ExpCTN_z',
             'EmoCTN_z',
             'PresCTN_z',
             'CNS_z',
             'EIDR_z')

cormatrix <- 
     as.matrix(val_data[,cor_cols])
            
correlations <-
     rcorr(cormatrix, type = "spearman")

corp <- 
     cor.mtest(cormatrix)

#format numbers
cor_table <-as.matrix( round(correlations$r,2))

#remove rownames and colnames
colnames(cor_table)<- rownames(cor_table)<- NULL

#remove leading zeros and add stars
n <- length(cor_cols)
for (c in 1:n) {
  for (r in 1:n) {
      pval <- correlations$P[r,c]
      stars <- ifelse(pval < .001, "***", ifelse(pval < .01, "** ", ifelse(pval < .05, "*  ", "   ")))
      coeff = sub("0*\\.",".",round(correlations$r,2)[r,c]) #remove leading zeros
      cor_table[r,c] = paste(c(coeff,stars),collapse='')
  }
}

cor_table[upper.tri(cor_table)] <- '' # erase the upper triangle
diag(cor_table) <- '-' # replace the diagonals by dash(-)




```



### Hypothesis 2.A - CNS

We predicted that:

-   The Deep Identity facet of the DEEP CTN scale will strongly
    correlate with the CNS

-   The other three facets will only weakly-moderately correlate with
    the CNS

*This is based on past research identifying the CNS as a uni-dimensional
measure of nature connectedness which focuses on the cognitive aspect of
connection to nature (Mayer & Frantz, 2004)*

### Hypothesis 2.B - EID-R

We similarly predicted that:

-   The Experience and Emotional facets of the DEEP CTN scale will
    strongly correlate with the EID-R

-   The Deep and Presence facets will weakly (or not at all) correlate.

*This is based on previous research which identified multiple dimensions
measuring enjoyment and appreciation of nature (Olivos & Aragones,
2011)*


A zero-order Spearman correlation of the four Deep CTN scale facets, the
CNS, and the EID-R found support for hypothesis 2A and partial
support for hypothesis 2B tested (see Table).

-   Hypothesis 2A is supported as the Deep CTN scale factor correlated
    strongly with the CNS, while the other three factors only correlated moderately.

-   Hypothesis 2B is partially supported. While the experiential factor
    did correlate strongly with the EID-R,t he emotional factor only correlated moderately. Additionally, the deep and presence facets also correlated moderately.

**Table 5. Spearman correlations between DEEP CTN facets and existing
measures of CTN**
```{r convergent validity cormatrix, echo=FALSE, message=FALSE, warning=FALSE}

#rename the columns in cor_table to match cor_cols
colnames(cor_table) <- cor_cols

cor_table %>% 
  as_tibble() %>% #mutate everything to numeric
    rownames_to_column() %>% 
    mutate(rowname = cor_cols) %>% 
    dplyr::select(rowname, CTN_z, DeepCTN_z, ExpCTN_z, EmoCTN_z, PresCTN_z) %>% 
    filter(rowname == "CNS_z" | rowname == "EIDR_z") %>% 
  mutate(rowname = case_when(rowname == "CNS_z" ~ "CNS",
                             rowname == "EIDR_z" ~ "EIDR")) %>%
  flextable() %>% 
  set_header_labels(rowname = " ", 
                    CTN_z = "Overall CTN", 
                    DeepCTN_z = "Deep", 
                    ExpCTN_z = "Experiential", 
                    EmoCTN_z = "Emotional", 
                    PresCTN_z = "Presence") %>% 
  add_footer_lines("Bold r values are the strongest factor correlation \n |0.1| ≤ r < |0.3| = Weak correlation \n|0.4| ≤ r < |0.7| = Moderate correlation \n|0.7| ≤ r = Strong correlation \n*** p < 0.001") %>%
  bold(i = 1, j = 3) %>% 
  bold(i = 2, j = 4) %>% 
  autofit()

```


## Hypothesis 3 - Predictive Validity

### Hypothesis 3.A - PEB

```{r cronbachs for peb, message=FALSE, warning=FALSE, include=FALSE}

peb_alpha <- 
  val_data %>% 
  dplyr::select(RPEBS_1, RPEBS_2, RPEBS_3, RPEBS_4, RPEBS_5, RPEBS_6, RPEBS_7, RPEBS_8, RPEBS_9, RPEBS_10, RPEBS_11, RPEBS_12, RPEBS_13, RPEBS_14, RPEBS_15, RPEBS_16, RPEBS_17, RPEBS_18, RPEBS_19, RPEBS_20) %>%
  ltm::cronbach.alpha()
```

```{r zero order correlation PEB, include=FALSE, echo=FALSE}

cor_cols = c('CTN_z',
             'DeepCTN_z',
             'ExpCTN_z',
             'EmoCTN_z',
             'PresCTN_z',
             'RPEBS_z')

cormatrix <- 
     as.matrix(val_data[,cor_cols])
            
correlations <-
     rcorr(cormatrix, type = "spearman")

corp <- 
     cor.mtest(cormatrix)

#format numbers
cor_table <-as.matrix( round(correlations$r,2))

#remove rownames and colnames
colnames(cor_table)<- rownames(cor_table)<- NULL

#remove leading zeros and add stars
n <- length(cor_cols)
for (c in 1:n) {
  for (r in 1:n) {
      pval <- correlations$P[r,c]
      stars <- ifelse(pval < .001, "***", ifelse(pval < .01, "** ", ifelse(pval < .05, "*  ", "   ")))
      coeff = sub("0*\\.",".",round(correlations$r,2)[r,c]) #remove leading zeros
      cor_table[r,c] = paste(c(coeff,stars),collapse='')
  }
}

cor_table[upper.tri(cor_table)] <- '' # erase the upper triangle
diag(cor_table) <- '-' # replace the diagonals by dash(-)



```


```{r linear regression with only dimensions predicting PEB, message=FALSE, warning=FALSE, include=FALSE}

dimensions_peb <-
      lm(RPEBS_z ~ DeepCTN_z + ExpCTN_z + EmoCTN_z + PresCTN_z, 
         data = val_data)

dimensions_peb_anova <-
     Anova(dimensions_peb, type = "II")

peb_r2 <-
     calc.relimp(dimensions_peb, type="lmg",
                 rela=F) #setting to T normalizes metrics to sum to 100%

p_vars <- c("Deep", "Experience", "Emotional", "Presence")
peb_rvalues <- tibble(round(peb_r2$lmg,2)) #partial R2 of all variables
peb_pvalues <- tibble(round(dimensions_peb_anova$`Pr(>F)`,2),
                         .name_repair = "universal") #p values

peb_tot_var<-round(peb_r2$R2, 2) #variance explained by model

#create table of R and P values
R2_peb_table <- 
     bind_cols(p_vars,peb_rvalues, peb_pvalues[-5,]) %>% 
     rename("Variable" = `...1`, "Partial R2" = `round(peb_r2$lmg, 2)`, 
            "p" = `round.dimensions_peb_anova..Pr..F....2.`)

#plotting effect sizes
#https://www.mihiretukebede.com/posts/2020-09-30-2020-09-30-plotting-model-coefficients-in-a-forest-plot/
dim_only_output <- broom::tidy(dimensions_peb)
dim_only_conf <- broom::tidy(dimensions_peb, conf.int = T)

model_dim_only <- forestmangr::round_df(dim_only_output, digits = 2)
model_dim_only <- model_dim_only[-1,] #remove the intercept 

coef_dim_only <- 
     coef(dimensions_peb)
ConfidenceInterval_dim_only <- 
     confint(dimensions_peb, level = 0.95)
coef_confint_dim_only <- 
     cbind(coef_dim_only, ConfidenceInterval_dim_only)%>% 
     as.data.frame()
coef_confint_dim_only <- 
     coef_confint_dim_only %>% 
     mutate(variable=c("Intercept", "Deep", "Experiential", "Emotional", "Presence"))


coef_confint_dim_only <- 
     coef_confint_dim_only %>% 
     rename(c("std Beta" = "coef_dim_only",
              "lower_bound" = `2.5 %`, 
              "upper_bound" = `97.5 %`))

# Reorder variables
col_order <- c("variable", "std Beta", "lower_bound", "upper_bound")
coef_confint_dim_only <- 
     coef_confint_dim_only[, col_order] #reorder variables in the data frame

coef_confint_dim_only <- 
     coef_confint_dim_only %>% 
  mutate_if(is.numeric, round, digits = 2) %>%  # round numeric into two significant digits 
  rename(Variable = variable)


peb_predict_table <-
bind_cols(coef_confint_dim_only[-1,], R2_peb_table[,-1]) %>% 
  mutate(`std Beta` = paste(`std Beta`, " (", lower_bound, " - ", upper_bound, ")")) %>% 
  dplyr::select(Variable, `Partial R2`, p, `std Beta`) %>%
  rename(`std Beta (99% CI)` = `std Beta`)

plot_model_dim_only <- coef_confint_dim_only[-1,] %>%  #remove row number 1 (The intercept) 
  ggplot(aes(x=reorder(Variable, `std Beta`), y=`std Beta`)) +
  geom_point(shape = 15,
             size  = 2,
             position = "dodge", 
             color="black") + 
  geom_errorbar(aes(ymin  = lower_bound,
                    ymax  = upper_bound),
                size  = 0.75,
                position = "dodge", 
                color="turquoise4",
                width = 0.5) +
  theme(axis.title = element_text(face = "bold")) +
  xlab("DEEP CTN Factor") + 
  ylab("\u03B2 coefficients with 95% CI") +
  coord_flip(ylim = c(-.5, .5)) + 
  geom_hline(yintercept = 0, color = "red", size = 0.5) +
   theme(axis.title = element_text(size = 17)) + 
  theme(axis.text = element_text(size = 14))  +
  theme(panel.background = element_rect(fill='transparent'), 
        plot.background = element_rect(fill='transparent', color=NA), 
        panel.grid.major = element_line(colour = "#ECEFF2"),
        panel.grid.minor = element_blank())



#ggsave("effects.png", plot_model_dim_only, dpi = 300)

```
We assessed the predictive validity of the new DEEP CTN scale (i.e., how
well our measure can predict participant scores on two theoretically
related constructs). The “gold standard” for predictive validity of CTN
measures is how well it predicts pro-environmental behavior (PEB)
(Clayton, 2003; Clayton et al., 2021; Mayer & Frantz, 2004; Tam, 2013).

We predicted that the DEEP CTN scale and its factors would correlate
moderately with PEB using the Recurring Pro-Environmental Scale (Brick
et al., 2017)(cronbach's alpha = `r round(peb_alpha$alpha,2)`). A
zero-order correlation confirmed moderate correlations between the
factors and PEB. However, we also predicted some variation of
correlations between the facets such that some are stronger predictors
than others. This was not supported as correlations ranged between r =
0.44 and r = 0.46 (See Table 6.)


**Table 6 Spearman correlations between DEEP CTN factors and existing
Pro-Environmental Behavior**
```{r zero order correlation PEB matrix table, echo=FALSE, include=TRUE, out.width="100%"}
#rename the columns in cor_table to match cor_cols
colnames(cor_table) <- cor_cols

cor_table %>% 
  as_tibble() %>% #mutate everything to numeric
    rownames_to_column() %>% 
    mutate(rowname = cor_cols) %>% 
    dplyr::select(rowname, CTN_z, DeepCTN_z, ExpCTN_z, EmoCTN_z, PresCTN_z) %>% 
    filter(rowname == "RPEBS_z") %>% 
  mutate(rowname = "PEB") %>%
  flextable() %>% 
  set_header_labels(rowname = " ", 
                    CTN_z = "Overall CTN", 
                    DeepCTN_z = "Deep", 
                    ExpCTN_z = "Experiential", 
                    EmoCTN_z = "Emotional", 
                    PresCTN_z = "Presence") %>% 
  add_footer_lines("|0.1| ≤ r < |0.3| = Weak correlation \n|0.4| ≤ r < |0.7| = Moderate correlation \n|0.7| ≤ r = Strong correlation \n*** p < 0.001") %>%
  autofit()


```
A linear regression predicting PEB from the four DEEP CTN factors explained `r peb_tot_var*100`% of the variance in the model. It showed that the emotional and presence factors explained a significant amount of unique variance in PEB (see Figure 6). 

**Figure 6. Effect sizes of DEEP CTN factors predicting Pro-environmental behavior**

```{r dimonly output, echo=FALSE, message=FALSE, warning=FALSE}

r_deep_peb <- as.list(pull(peb_rvalues[1,1]))$DeepCTN_z #ns
r_exp_peb <- as.list(pull(peb_rvalues[2,1]))$ExpCTN_z #ns
r_emo_peb <- as.list(pull(peb_rvalues[3,1]))$EmoCTN_z #***
r_pres_peb <- as.list(pull(peb_rvalues[4,1]))$PresCTN_z #**

grp <- c(paste("r = ", r_exp_peb),
         paste("r = ", r_deep_peb), 
         paste("r = ", r_pres_peb, "**"),
         paste("r = ", r_emo_peb, "***"))

plot_model_dim_only <-
plot_model_dim_only +
  geom_text(aes(label = grp), 
                position = position_dodge(0.9),
                vjust = -1.5)


plot_model_dim_only
```

### Hypothesis 3.B - Well-Being

```{r wellbeing cronbachs, include=FALSE}

wb_alpha <-
  val_data %>% 
  dplyr::select(RYFF_1_autonomy, RYFF_2_autonomy, RYFF_3_autonomy, 
         RYFF_4_enviromastery, RYFF_5_enviromastery, RYFF_6_enviromastery,
         RYFF_7_growth, RYFF_8_growth, RYFF_9_growth, 
         RYFF_10_relations, RYFF_11_relations, RYFF_12_relations,
         RYFF_13_purpose, RYFF_14_purpose, RYFF_15_purpose, 
         RYFF_16_selfaccept, RYFF_17_selfaccept, RYFF_18_selfaccept, 
         
         PANAS_1, PANAS_2, PANAS_3, PANAS_4, PANAS_5, 
         PANAS_6, PANAS_7, PANAS_8, PANAS_9, PANAS_10,
         
         VITALITY_1, VITALITY_2, VITALITY_3, 
         VITALITY_4, VITALITY_5, VITALITY_6) %>%
  ltm::cronbach.alpha()
```

Nature connectedness has also been shown to relate to various measures
of psychological well-being (Capaldi et al., 2014; Pritchard et al.,
2020). To measure well-being we used a composite measure from three
established measures of well-being: 1) the Ryff Well-being Scale (Ryff &
Keyes, 1995); 2) the positive affect sub-scale of the PANAS (Watson et
al., 1988); and 3) the Subjective Vitality Scale (Ryan & Frederick,
1997). The Cronbach’s Alpha for this composite measure is
`r round(wb_alpha$alpha,2)`.

We predicted that the DEEP CTN scale and its factors would correlate
moderately with well-being. A zero-order correlation confirmed only
weak-moderate correlations between the factors and well-being. Similarly
to predicting PEB there as consistency across the factors to predict
well-being. This countered our prediction that there would be variation
among the factors to predict well-being, as correlations ranged between
r = 0.17 and r = 0.42 (See Table 7.)



```{r zero order correlation WB, include=FALSE, echo=FALSE}

cor_cols = c('CTN_z',
             'DeepCTN_z',
             'ExpCTN_z',
             'EmoCTN_z',
             'PresCTN_z',
             'WB')

cormatrix <- 
     as.matrix(val_data[,cor_cols])
            
correlations <-
     rcorr(cormatrix, type = "spearman")

corp <- 
     cor.mtest(cormatrix)

#format numbers
cor_table <-as.matrix( round(correlations$r,2))

#remove rownames and colnames
colnames(cor_table)<- rownames(cor_table)<- NULL

#remove leading zeros and add stars
n <- length(cor_cols)
for (c in 1:n) {
  for (r in 1:n) {
      pval <- correlations$P[r,c]
      stars <- ifelse(pval < .001, "***", ifelse(pval < .01, "** ", ifelse(pval < .05, "*  ", "   ")))
      coeff = sub("0*\\.",".",round(correlations$r,2)[r,c]) #remove leading zeros
      cor_table[r,c] = paste(c(coeff,stars),collapse='')
  }
}

cor_table[upper.tri(cor_table)] <- '' # erase the upper triangle
diag(cor_table) <- '-' # replace the diagonals by dash(-)



```

**Table 7. Zero-order correlations between DEEP CTN factors and
Well-being**

```{r zero order correlation WB table, echo=FALSE, include=TRUE, out.width="100%"}
#rename the columns in cor_table to match cor_cols
colnames(cor_table) <- cor_cols

cor_table %>% 
  as_tibble() %>% #mutate everything to numeric
    rownames_to_column() %>% 
    mutate(rowname = cor_cols) %>% 
    dplyr::select(rowname, CTN_z, DeepCTN_z, ExpCTN_z, EmoCTN_z, PresCTN_z) %>% 
    filter(rowname == "WB") %>% 
  mutate(rowname = "Well-being") %>%
  flextable() %>% 
  set_header_labels(rowname = " ", 
                    CTN_z = "Overall CTN", 
                    DeepCTN_z = "Deep", 
                    ExpCTN_z = "Experiential", 
                    EmoCTN_z = "Emotional", 
                    PresCTN_z = "Presence") %>% 
  add_footer_lines("|0.1| ≤ r < |0.3| = Weak correlation \n|0.4| ≤ r < |0.7| = Moderate correlation \n|0.7| ≤ r = Strong correlation \n** p < 0.01\n*** p < 0.001") %>%
  autofit()
```

```{r linear regression with only dimensions predicting WB, message=FALSE, warning=FALSE, include=FALSE}

#WB is already standardized as a z score
dimensions_wb <-
      lm(WB ~ DeepCTN_z + ExpCTN_z + EmoCTN_z + PresCTN_z, 
         data = val_data)

dimensions_wb_anova <-
     Anova(dimensions_wb, type = "II")

wb_r2 <-
     calc.relimp(dimensions_wb, type="lmg",
                 rela=F) #setting to T normalizes metrics to sum to 100%

p_vars <- c("Deep", "Experience", "Emotional", "Presence")
wb_rvalues <- tibble(round(wb_r2$lmg,2)) #partial R2 of all variables
wb_pvalues <- tibble(round(dimensions_wb_anova$`Pr(>F)`,2),
                         .name_repair = "universal") #p values

wb_tot_var<-round(wb_r2$R2, 2) #variance explained by model

#create table of R and P values
R2_wb_table <- 
     bind_cols(p_vars,wb_rvalues, wb_pvalues[-5,]) %>% 
     rename("Variable" = `...1`, "Partial R2" = `round(wb_r2$lmg, 2)`, 
            "p" = `round.dimensions_wb_anova..Pr..F....2.`)

#plotting effect sizes
#https://www.mihiretukebede.com/posts/2020-09-30-2020-09-30-plotting-model-coefficients-in-a-forest-plot/
dim_only_output <- broom::tidy(dimensions_wb)
dim_only_conf <- broom::tidy(dimensions_wb, conf.int = T)

model_dim_only <- forestmangr::round_df(dim_only_output, digits = 2)
model_dim_only <- model_dim_only[-1,] #remove the intercept 

coef_dim_only <- 
     coef(dimensions_wb)
ConfidenceInterval_dim_only <- 
     confint(dimensions_wb, level = 0.95)
coef_confint_dim_only <- 
     cbind(coef_dim_only, ConfidenceInterval_dim_only)%>% 
     as.data.frame()
coef_confint_dim_only <- 
     coef_confint_dim_only %>% 
     mutate(variable=c("Intercept", "Deep", "Experiential", "Emotional", "Presence"))


coef_confint_dim_only <- 
     coef_confint_dim_only %>% 
     rename(c("std Beta" = "coef_dim_only",
              "lower_bound" = `2.5 %`, 
              "upper_bound" = `97.5 %`))

# Reorder variables
col_order <- c("variable", "std Beta", "lower_bound", "upper_bound")
coef_confint_dim_only <- 
     coef_confint_dim_only[, col_order] #reorder variables in the data frame

coef_confint_dim_only <- 
     coef_confint_dim_only %>% 
  mutate_if(is.numeric, round, digits = 2) %>%  # round numeric into two significant digits 
  rename(Variable = variable)


wb_regression_table <-
  bind_cols(coef_confint_dim_only[-1,], R2_wb_table[,-1]) %>% 
  relocate(c(`Partial R2`, p), .after = Variable) %>% 
  mutate(`std Beta` = paste(`std Beta`, " (", lower_bound, " - ", upper_bound, ")")) %>% 
  dplyr::select(Variable, `Partial R2`, p, `std Beta`) %>%
  rename(`std Beta (99% CI)` = `std Beta`)

       


plot_model_dim_only <- 
  bind_cols(coef_confint_dim_only[-1,], R2_wb_table[,-1])  %>%  #remove row number 1 (The intercept) 
  mutate(rsig = case_when(Variable == "Deep" ~  
                            paste0(as.list(pull(wb_rvalues[1,1]))$DeepCTN_z, "***"),
                          Variable == "Experiential" ~
                            paste0(as.list(pull(wb_rvalues[2,1]))$ExpCTN_z),
                          Variable == "Emotional" ~
                            paste0(as.list(pull(wb_rvalues[3,1]))$EmoCTN_z, "**"),
                          Variable == "Presence" ~
                            paste0(as.list(pull(wb_rvalues[4,1]))$PresCTN_z, "***"))) %>% 
  ggplot(aes(x=reorder(Variable, `std Beta`), y=`std Beta`)) +
  geom_point(shape = 15,
             size  = 2,
             position = "dodge", 
             color="black") + 
  geom_errorbar(aes(ymin  = lower_bound,
                    ymax  = upper_bound),
                size  = 0.75,
                position = "dodge", 
                color="turquoise4",
                width = 0.5) +
  geom_text(aes(label = rsig), 
                position = position_dodge(0.9),
                vjust = -1.5) +
  theme(axis.title = element_text(face = "bold")) +
  xlab("DEEP CTN Factor") + 
  ylab("\u03B2 coefficients with 95% CI") +
  coord_flip(ylim = c(-.5, .5)) + 
  geom_hline(yintercept = 0, color = "red", size = 0.5) +
   theme(axis.title = element_text(size = 17)) + 
  theme(axis.text = element_text(size = 14))  +
  theme(panel.background = element_rect(fill='transparent'), 
        plot.background = element_rect(fill='transparent', color=NA), 
        panel.grid.major = element_line(colour = "#ECEFF2"),
        panel.grid.minor = element_blank())



#ggsave("effects.png", plot_model_dim_only, dpi = 300)

```

A linear regression predicting well-being from the four DEEP CTN factors accounted for  `r wb_tot_var*100`% of the variance in the model. It showed that presence, deep, and emotional explained a unique amount of variance in well-being. Interestingly, while deep and presence factors showed a positive relationship with well-being, emotional CTN had a negative relationship (see Figure 7).

**Figure 7. Linear regression predicting Well-being from ONLY DEEP CTN
factors**

```{r dimonly output WB, echo=FALSE, message=FALSE, warning=FALSE}

plot_model_dim_only 

```

## Hypothesis 4 - Incremental Validity

We explored if the DEEP CTN scale and its facets would perform above and
beyond existing CTN scales (i.e., CNS and EID-R) when predicting PEB.

### Hypothesis 4.A - PEB

We predicted that one or more of the factors of the DEEP CTN scale would
be the strongest predictor of PEB compared to the CNS and the EID-R. A
linear regression model predicting PEB from the four factors of the DEEP
CTN scale and two existing CTN measures (CNS and EIDR). These were all
entered simultaneously to determine the amount of unique variance each
predictor accounted for. Note that because overall CTN was highly
intercorrelated with the factors of the scale, it was left out and only
the four dimensions were included.

The results of the linear regression to predict PEB support our
prediction. When entered simultaneously into a regression model, both
the emotional and presence factors of the DEEP CTN Scale stayed significant predictors of PEB at a corrected alpha to account for family-wise error (see Table 6.)

```{r predictive validity PEB,include=FALSE, warning=FALSE}

model_peb <- 
        lm(RPEBS_z ~ DeepCTN_z + ExpCTN_z + EmoCTN_z + PresCTN_z + 
             CNS_z + EIDR_z, data = val_data)

anova_model_peb <-
     Anova(model_peb, type = "II")


incremental_r2 <-
     calc.relimp(model_peb, type="lmg",
                 rela=F) #setting to T normalizes metrics to sum to 100%

incremental_vars <- c("deep_ctn_z", "exp_ctn_z", "emo_ctn_z", "presc_ctn_z", "CTN_Z", "EIDR_Z")
incremental_rvalues <- tibble(round(incremental_r2$lmg,2)) #partial R2 of all variables
incremental_pvalues <- tibble(round(anova_model_peb$`Pr(>F)`,2),
                         .name_repair = "universal") #p values

inc_tot_var <-round(incremental_r2$R2, 2) #variance explained by model



#create table of R and P values
R2_incremental_table <- 
     bind_cols(incremental_vars, incremental_rvalues, incremental_pvalues[-7,]) %>% 
     rename("variable" = `...1`, "Partial R2" = `round(incremental_r2$lmg, 2)`, 
            "p" = `round.anova_model_peb..Pr..F....2.`)


#plotting effect sizes
#https://www.mihiretukebede.com/posts/2020-09-30-2020-09-30-plotting-model-coefficients-in-a-forest-plot/
model_peb_output <- broom::tidy(model_peb)
model_peb_conf <- broom::tidy(model_peb, conf.int = T)

model_peb_out <- forestmangr::round_df(model_peb_conf, digits = 2)
model_peb_out <- model_peb_out[-1,] #remove the intercept 

coef_peb <- 
     coef(model_peb)
ConfidenceInterval_peb <- 
     confint(model_peb, level = 0.95)
coef_confint_peb <- 
     cbind(coef_peb, ConfidenceInterval_peb)%>% 
     as.data.frame()
coef_confint_peb <- 
     coef_confint_peb %>% 
     mutate(variable=rownames(coef_confint_peb))


coef_confint_peb <- 
     coef_confint_peb %>% 
     rename(c("std Beta" = "coef_peb",
              "lower_bound" = `2.5 %`, 
              "upper_bound" = `97.5 %`))

# Reorder variables
col_order <- c("variable", "std Beta", "lower_bound", "upper_bound")
coef_confint_peb <- 
     coef_confint_peb[, col_order] #reorder variables in the data frame

coef_confint_peb <- 
     coef_confint_peb %>% 
  mutate_if(is.numeric, round, digits = 2) # round numeric into two significant digits 

incremental_peb_table <-
bind_cols(coef_confint_peb[-1,], R2_incremental_table[,-1]) %>% 
     relocate(c(`Partial R2`, p), .after = variable) %>% 
  mutate(`std Beta` = paste(`std Beta`, " (", lower_bound, " - ", upper_bound, ")")) %>% 
  dplyr::select(variable, `Partial R2`, p, `std Beta`) %>%
  rename(`std Beta (99% CI)` = `std Beta`)



plot_model_peb <- coef_confint_peb[-1,] %>%  #remove row number 1 (The intercept) 
  ggplot(aes(x=reorder(variable, `std Beta`), y=`std Beta`)) +
     geom_hline(yintercept = 0, color = "red", size = 1) +
  geom_point(shape = 15,
             size  = 4,
             position = "dodge", 
             color="black") + 
  geom_errorbar(aes(ymin  = lower_bound,
                    ymax  = upper_bound),
                size  = 1,
                position = "dodge", 
                color="turquoise4") +
  theme(axis.title = element_text(face = "bold")) +
  xlab("Variables") + ylab("\u03B2 coeffecients with 95% CI") +
  coord_flip(ylim = c(-.5, .5)) + 
   theme(axis.title = element_text(size = 17)) + 
  theme(axis.text = element_text(size = 14)) 
```

**Table 6. Linear regression predicting PEB from DEEP CTN factors, CNS,
and EID-R**

```{r model PEB table, echo=FALSE, warning=FALSE}

peb_predict_table <-
  peb_predict_table %>% 
    as_tibble()

incremental_peb_table <-
  incremental_peb_table %>% 
    as_tibble() %>% 
    rename(Variable = variable) %>% 
    mutate(Variable = case_when(Variable == "DeepCTN_z" ~ paste("Deep"),
                                Variable == "ExpCTN_z" ~ paste("Experiential"),
                                Variable == "EmoCTN_z" ~ paste("Emotional"),
                                Variable == "PresCTN_z" ~ paste("Presence"),
                                Variable == "CNS_z" ~ paste("CNS"),
                                Variable == "EIDR_z" ~ paste("EIDR")))

full_join(peb_predict_table, incremental_peb_table, by = "Variable", suffix = c("_1", "_2")) %>% 
  flextable() %>% 
  autofit() %>% 
  add_header_row(value = c(" ","Step 1", "Step 2"), colwidths = c(1,3,3)) %>% 
  set_header_labels(Variable = "Variable", `Partial R2_1` = "Partial R2", p_1 = "p", 
                    `std Beta (99% CI)_1` = "std Beta (99% CI)",
                    `Partial R2_2` = "Partial R2", p_2 = "p", 
                    `std Beta (99% CI)_2` = "std Beta (99% CI)") %>% 
  align(part = "header", align = "center") %>% 
  align(j = 2:7, align = "center") %>% 
  bold(j = 3:4, i = 3:4, part = "body") %>% 
  bold(j = 5:7, i = 3:5, part = "body") %>% 
  bold(j = 1, i = 3:5) %>% 
  add_body_row(top = FALSE, 
               values = c("Model R2", peb_tot_var, inc_tot_var),
               colwidths = c(1,3,3)) %>% 
  align(j = 2:7, align = "right") %>%
     add_footer_lines(value = as_paragraph("Bold indicates significant p value and CI \n 
                                           To account for the familywise error rate of multiple tests, we used a corrected alpha of 0.025 as the critical p-value \n
                                           std Beta < 0.29 = small \n 
                                   std Beta < 0.49 = medium \n 
                                   std Beta > 0.50 = large")) 



```

### Hypothesis 4.B - Well-being


We also explored if the DEEP CTN scale and its facets would perform
above and beyond existing CTN scales (i.e., CNS and EID-R) when
predicting Well-being. We predicted that one or more of the factors of
the DEEP CTN scale would be the strongest predictor of psychological
well-being compared to the CNS and the EID-R. Similar to the regression
to predict PEB, only the factors of CTN were entered in the model due to
the high inter-correlation of the overall CTN measure with its own
factors.

The results of the linear regression to predict well-being show that emotional and presence remain significant predictors at a correct alpha, however the deep CTN factor is no longer significant (see Table 7). 


```{r predictive validity WB,include=FALSE, warning=FALSE}

model_wb <- 
        lm(WB ~ DeepCTN_z + ExpCTN_z + EmoCTN_z + PresCTN_z + 
             CNS_z + EIDR_z, data = val_data)

anova_model_wb <-
     Anova(model_wb, type = "II")


incremental_r2 <-
     calc.relimp(model_wb, type="lmg",
                 rela=F) #setting to T normalizes metrics to sum to 100%

incremental_vars <- c("deep_ctn_z", "exp_ctn_z", "emo_ctn_z", "presc_ctn_z", "CTN_Z", "EIDR_Z")
incremental_rvalues <- tibble(round(incremental_r2$lmg,2)) #partial R2 of all variables
incremental_pvalues <- tibble(round(anova_model_wb$`Pr(>F)`,2),
                         .name_repair = "universal") #p values

inc_tot_var <-round(incremental_r2$R2, 2) #variance explained by model



#create table of R and P values
R2_incremental_table <- 
     bind_cols(incremental_vars, incremental_rvalues, incremental_pvalues[-7,]) %>% 
     rename("variable" = `...1`, "Partial R2" = `round(incremental_r2$lmg, 2)`, 
            "p" = `round.anova_model_wb..Pr..F....2.`)


#plotting effect sizes
#https://www.mihiretukebede.com/posts/2020-09-30-2020-09-30-plotting-model-coefficients-in-a-forest-plot/
model_wb_output <- broom::tidy(model_wb)
model_wb_conf <- broom::tidy(model_wb, conf.int = T)

model_wb_out <- forestmangr::round_df(model_wb_conf, digits = 2)
model_wb_out <- model_wb_out[-1,] #remove the intercept 

coef_wb <- 
     coef(model_wb)
ConfidenceInterval_wb <- 
     confint(model_wb, level = 0.95)
coef_confint_wb <- 
     cbind(coef_wb, ConfidenceInterval_wb)%>% 
     as.data.frame()
coef_confint_wb <- 
     coef_confint_wb %>% 
     mutate(variable=rownames(coef_confint_wb))


coef_confint_wb <- 
     coef_confint_wb %>% 
     rename(c("std Beta" = "coef_wb",
              "lower_bound" = `2.5 %`, 
              "upper_bound" = `97.5 %`))

# Reorder variables
col_order <- c("variable", "std Beta", "lower_bound", "upper_bound")
coef_confint_wb <- 
     coef_confint_wb[, col_order] #reorder variables in the data frame

incremental_wb <- 
  bind_cols(coef_confint_wb[-1,], R2_incremental_table[,-1]) %>% 
  mutate_if(is.numeric, round, digits = 2) %>% 
  mutate(`std Beta` = paste(`std Beta`, " (", lower_bound, " - ", upper_bound, ")")) %>% 
  dplyr::select(variable, `Partial R2`, p, `std Beta`) %>%
  rename(`std Beta (99% CI)` = `std Beta`)


plot_model_wb <- coef_confint_wb[-1,] %>%  #remove row number 1 (The intercept) 
  ggplot(aes(x=reorder(variable, `std Beta`), y=`std Beta`)) +
     geom_hline(yintercept = 0, color = "red", size = 1) +
  geom_point(shape = 15,
             size  = 4,
             position = "dodge", 
             color="black") + 
  geom_errorbar(aes(ymin  = lower_bound,
                    ymax  = upper_bound),
                size  = 1,
                position = "dodge", 
                color="turquoise4") +
  theme(axis.title = element_text(face = "bold")) +
  xlab("Variables") + ylab("\u03B2 coeffecients with 95% CI") +
  coord_flip(ylim = c(-.5, .5)) + 
   theme(axis.title = element_text(size = 17)) + 
  theme(axis.text = element_text(size = 14)) 
```

**Table 7. Linear regression predicting Well-being from DEEP CTN
factors, CNS, and EID-R**

```{r model WB plots, echo=FALSE, warning=FALSE}

wb_regression_table <-
  wb_regression_table %>% 
    as_tibble()

incremental_wb <-
  incremental_wb %>% 
    as_tibble() %>% 
    rename(Variable = variable) %>% 
    mutate(Variable = case_when(Variable == "DeepCTN_z" ~ paste("Deep"),
                                Variable == "ExpCTN_z" ~ paste("Experiential"),
                                Variable == "EmoCTN_z" ~ paste("Emotional"),
                                Variable == "PresCTN_z" ~ paste("Presence"),
                                Variable == "CNS_z" ~ paste("CNS"),
                                Variable == "EIDR_z" ~ paste("EIDR")))

full_join(wb_regression_table, incremental_wb, by = "Variable", suffix = c("_1", "_2")) %>% 
  flextable() %>% 
  autofit() %>% 
  add_header_row(value = c(" ","Step 1", "Step 2"), colwidths = c(1,3,3)) %>% 
  set_header_labels(Variable = "Variable", `Partial R2_1` = "Partial R2", p_1 = "p", 
                    `std Beta (99% CI)_1` = "std Beta (99% CI)",
                    `Partial R2_2` = "Partial R2", p_2 = "p", 
                    `std Beta (99% CI)_2` = "std Beta (99% CI)") %>% 
  align(part = "header", align = "center") %>% 
  align(j = 2:7, align = "center") %>% 
  bold(i = c(1, 3,4), j = 2:4, part = "body") %>% 
  bold(i = 3:5, j = 5:7, part = "body") %>% 
  bold(j = 1, i = c(1,3,4,5)) %>% 
  add_body_row(top = FALSE, 
               values = c("Model R2", wb_tot_var, inc_tot_var),
               colwidths = c(1,3,3)) %>% 
  align(j = 2:7, align = "right") %>%
     add_footer_lines(value = as_paragraph("Bold indicates significant p value and CI \n 
                                           To account for the familywise error rate of multiple tests, we used a corrected alpha of 0.025 as the critical p-value \n
                                           std Beta < 0.29 = small \n 
                                   std Beta < 0.49 = medium \n 
                                   std Beta > 0.50 = large")) 




```

## Hypothesis 5 - Robustness

We also tested the robustness of our new DEEP CTN scale, by testing if
the DEEP CTN scale and its factors are significant predictors of both
PEB & well-being after controlling for known covariates of these
outcomes (e.g., interconnected world-views, political ideology, gender,
age, and socio-economic status (SES)).

We fist inspected a zero order correlation to identify which covariates
should be included. The decision to include variables is based on
whether they are:

1.  Strongly correlated with the outcome measure (PEB or Well-being) AND

2.  Weakly correlated with the Deep CTN Scale

Do so would reduce variance in the outcome variable and therefore
enhance the likelihood of seeing significant effects of the DEEP CTN
scale.

Further, if an additional variable is:

1.  Strongly correlated with BOTH the outcome variable (PEB or
    Well-being) AND

2.  the Deep CTN Scale,

its inclusion in the model could address potential mediating effects
regarding the relationship between the Deep CTN Scale and the outcome
variable of interest. In either case this would suggest it’s important
to include as a covariate.

This resulted in including the following when predicting **PEB**:
-  Worldviews
-  Age

As well as including the following when predicting **well-being**:
-  Worldviews
-  Politics 
-  Age 

```{r Robustness Covariates, echo=FALSE, include=FALSE}
cor_cols_rob <- c('CTN_z',
             'DeepCTN_z',
             'ExpCTN_z',
             'EmoCTN_z',
             'PresCTN_z',
             'RPEBS_z',
             'WB',
             'PI_interconnect_z',
             'pol_z',
             'age',
             'gender_dummy',
             'ses_z')

cormatrix <- 
     as.matrix(val_data[,cor_cols_rob])
            
correlations <-
     rcorr(cormatrix, type = "spearman")


#format numbers
cor_table_rob <-as.matrix( round(correlations$r,2))

#remove rownames and colnames
colnames(cor_table_rob)<- rownames(cor_table_rob)<- NULL

#remove leading zeros and add stars
n <- length(cor_cols_rob)
for (c in 1:n) {
  for (r in 1:n) {
      pval <- correlations$P[r,c]
      stars <- ifelse(pval < .001, "***", ifelse(pval < .01, "** ", ifelse(pval < .05, "*  ", "   ")))
      coeff = sub("0*\\.",".",round(correlations$r,2)[r,c]) #remove leading zeros
      cor_table_rob[r,c] = paste(c(coeff,stars),collapse='')
  }
}

cor_table_rob[upper.tri(cor_table_rob)] <- '' # erase the upper triangle
diag(cor_table_rob) <- '-' # replace the diagonals by dash(-)


```

**Table 8. Zero-order correlations between DEEP CTN Scale factors and covariates**
```{r full zero-order correlation, echo=FALSE}
#rename the columns in cor_table to match cor_cols
colnames(cor_table_rob) <- cor_cols_rob

cor_table_rob %>% 
  as_tibble() %>% #mutate everything to numeric
    rownames_to_column() %>% 
    mutate(rowname = cor_cols_rob) %>% 
    dplyr::select(rowname, CTN_z, DeepCTN_z, ExpCTN_z, EmoCTN_z, PresCTN_z, RPEBS_z, WB) %>% 
    filter(rowname == "PI_interconnect_z" |
             rowname == "pol_z" |
             rowname == "age" |
             rowname == "gender_dummy" |
             rowname == "ses_z") %>% 
  mutate(rowname = c("Worldviews", "Politics", "Age", "Gender", "SES")) %>%
  flextable() %>% 
  set_header_labels(rowname = " ", 
                    CTN_z = "Overall CTN", 
                    DeepCTN_z = "Deep", 
                    ExpCTN_z = "Experiential", 
                    EmoCTN_z = "Emotional", 
                    PresCTN_z = "Presence",
                    RPEBS_z = "PEB",
                    WB = "Well-being") %>% 
    bold(i = 1, j = c(1:8)) %>% #Worldviews
  bold(i = 2, j = c(1,5,8)) %>% #politics
  bold(i = 3, j = c(1,2,3,4,6,7,8)) %>% #age
  add_footer_lines("|0.1| ≤ r < |0.3| = Weak correlation \n|0.4| ≤ r < |0.7| = Moderate correlation \n|0.7| ≤ r = Strong correlation \n*** p < 0.001") %>%
  autofit()

```

### Hypothesis 5.A - PEB

```{r Robustness dimsonly, echo=FALSE, message=FALSE, warning=FALSE}

robust_model_peb <-
      lm(RPEBS_z ~ DeepCTN_z + ExpCTN_z + EmoCTN_z + PresCTN_z + 
            PI_interconnect_z + age,
         data = val_data)


robust_anova_peb <-
     Anova(robust_model_peb, type = "II")


robust_r2 <-
     calc.relimp(robust_model_peb, type="lmg",
                 rela=F) #setting to T normalizes metrics to sum to 100%

robust_rvalues <- tibble(round(robust_r2$lmg,2)) #partial R2 of all variables
robust_pvalues <- tibble(round(robust_anova_peb$`Pr(>F)`,2),
                         .name_repair = "universal") #p values
vars <- tibble(c("deep_ctn_z", "exp_ctn_z", "emo_ctn_z", "presc_ctn_z", "PI_connect_Z", "age"))

robust_tot_var<- round(robust_r2$R2, 2) #variance explained by model



#create table of R and P values
R2_incremental_peb_robust <- 
     bind_cols(vars, robust_rvalues, robust_pvalues[-7,]) %>% 
     dplyr::rename("variable" = `c(...)`, 
            "Partial R2" = `round(robust_r2$lmg, 2)`, 
            "p" = `round.robust_anova_peb..Pr..F....2.`)



     
#plotting effect sizes
#https://www.mihiretukebede.com/posts/2020-09-30-2020-09-30-plotting-model-coefficients-in-a-forest-plot/
model_robustPEB_output <- broom::tidy(robust_model_peb)
model_robustPEB_conf <- broom::tidy(robust_model_peb, conf.int = T)

model_robustPEB <- forestmangr::round_df(model_robustPEB_conf, digits = 2)
model_robustPEB <- model_robustPEB[-1,] #remove the intercept 

coef_robustPEB <- 
     coef(robust_model_peb)
ConfidenceInterval_robustPEB <- 
     confint(robust_model_peb, level = 0.95)
coef_confint_robustPEB <- 
     cbind(coef_robustPEB, ConfidenceInterval_robustPEB)%>% 
     as.data.frame()
coef_confint_robustPEB <- 
     coef_confint_robustPEB %>% 
     mutate(variable=rownames(coef_confint_robustPEB))


coef_confint_robustPEB <- 
     coef_confint_robustPEB %>% 
     rename(c("std Beta" = "coef_robustPEB",
              "lower_bound" = `2.5 %`, 
              "upper_bound" = `97.5 %`))

# Reorder variables
col_order <- c("variable", "std Beta", "lower_bound", "upper_bound")
coef_confint_robustPEB <- 
     coef_confint_robustPEB[, col_order] #reorder variables in the data frame

coef_confint_robustPEB <- 
     coef_confint_robustPEB %>% 
  mutate_if(is.numeric, round, digits = 2) # round numeric into two significant digits 


peb_robust_table <-
  bind_cols(coef_confint_robustPEB[-1,], R2_incremental_peb_robust[,-1]) %>% 
  rename("Variable" = "variable") %>%
  mutate(`std Beta` = paste(`std Beta`, " (", lower_bound, " - ", upper_bound, ")"),
         Variable = case_when(Variable == "DeepCTN_z" ~ "Deep",
                              Variable == "ExpCTN_z" ~ "Experiential",
                              Variable == "EmoCTN_z" ~ "Emotional",
                              Variable == "PresCTN_z" ~ "Presence",
                              Variable == "PI_interconnect_z" ~ "Worldviews",
                              Variable == "age" ~ "Age",
                              .default = paste(Variable))) %>% 
  dplyr::select(Variable, `Partial R2`, p, `std Beta`) %>%
  rename(`std Beta (99% CI)` = `std Beta`) %>% 
  as_tibble()


plot_model_robustPEB <- coef_confint_robustPEB[-1,] %>%  #remove row number 1 (The intercept) 
  ggplot(aes(x=reorder(variable, `std Beta`), y=`std Beta`)) +
  geom_point(shape = 15,
             size  = 4,
             position = "dodge", 
             color="black") + 
  geom_errorbar(aes(ymin  = lower_bound,
                    ymax  = upper_bound),
                size  = 1,
                position = "dodge", 
                color="turquoise4") +
  theme(axis.title = element_text(face = "bold")) +
  xlab("Variables") + ylab("Beta coeffecients with 95% CI") +
  coord_flip(ylim = c(-.5, .5)) + 
  geom_hline(yintercept = 0, color = "red", size = 1) +
   theme(axis.title = element_text(size = 17)) + 
  theme(axis.text = element_text(size = 14)) 

```


```{r Robustness Existing measures, eval=FALSE, warning=FALSE, include=FALSE}

robust_model_peb <-
      lm(RPEBS_z ~ DeepCTN_z + ExpCTN_z + EmoCTN_z + PresCTN_z + 
             CNS_z + EIDR_z + 
            PI_interconnect_z, data = val_data)


robust_anova_peb <-
     Anova(robust_model_peb, type = "II")


robust_r2 <-
     calc.relimp(robust_model_peb, type="lmg",
                 rela=F) #setting to T normalizes metrics to sum to 100%

robust_rvalues <- tibble(round(robust_r2$lmg,2)) #partial R2 of all variables
robust_pvalues <- tibble(round(robust_anova_peb$`Pr(>F)`,2),
                         .name_repair = "universal") #p values
vars <- tibble(c("deep_ctn_z", "exp_ctn_z", "emo_ctn_z", "presc_ctn_z", "CTN_Z", "EIDR_Z", "PI_connect_Z"))

robust_tot_var<- round(robust_r2$R2, 2) #variance explained by model



#create table of R and P values
R2_incremental_peb_robust <- 
     bind_cols(vars, robust_rvalues, robust_pvalues[-8,])%>% 
     rename("variable" = `c(...)`, "Partial R2" = `round(robust_r2$lmg, 2)`, 
            "p" = `round.robust_anova_peb..Pr..F....2.`)
     
#plotting effect sizes
#https://www.mihiretukebede.com/posts/2020-09-30-2020-09-30-plotting-model-coefficients-in-a-forest-plot/
model_robustPEB_output <- broom::tidy(robust_model_peb)
model_robustPEB_conf <- broom::tidy(robust_model_peb, conf.int = T)

model_robustPEB <- forestmangr::round_df(model_robustPEB_conf, digits = 2)
model_robustPEB <- model_robustPEB[-1,] #remove the intercept 

coef_robustPEB <- 
     coef(robust_model_peb)
ConfidenceInterval_robustPEB <- 
     confint(robust_model_peb, level = 0.95)
coef_confint_robustPEB <- 
     cbind(coef_robustPEB, ConfidenceInterval_robustPEB)%>% 
     as.data.frame()
coef_confint_robustPEB <- 
     coef_confint_robustPEB %>% 
     mutate(variable=rownames(coef_confint_robustPEB))


coef_confint_robustPEB <- 
     coef_confint_robustPEB %>% 
     rename(c("std Beta" = "coef_robustPEB",
              "lower_bound" = `2.5 %`, 
              "upper_bound" = `97.5 %`))

# Reorder variables
col_order <- c("variable", "std Beta", "lower_bound", "upper_bound")
coef_confint_robustPEB <- 
     coef_confint_robustPEB[, col_order] #reorder variables in the data frame

coef_confint_robustPEB <- 
     coef_confint_robustPEB %>% 
  mutate_if(is.numeric, round, digits = 2) # round numeric into two significant digits 

plot_model_robustPEB <- coef_confint_robustPEB[-1,] %>%  #remove row number 1 (The intercept) 
  ggplot(aes(x=reorder(variable, `std Beta`), y=`std Beta`)) +
  geom_point(shape = 15,
             size  = 4,
             position = "dodge", 
             color="black") + 
  geom_errorbar(aes(ymin  = lower_bound,
                    ymax  = upper_bound),
                size  = 1,
                position = "dodge", 
                color="turquoise4") +
  theme(axis.title = element_text(face = "bold")) +
  xlab("Variables") + ylab("Beta coeffecients with 95% CI") +
  coord_flip(ylim = c(-.5, .5)) + 
  geom_hline(yintercept = 0, color = "red", size = 1) +
   theme(axis.title = element_text(size = 17)) + 
  theme(axis.text = element_text(size = 14)) 

```

```{r robust anova table, echo=FALSE, message=FALSE, warning=FALSE}
#Compare models
comparison <-
anova(dimensions_peb, robust_model_peb)

robust_peb_f <- round(comparison$F[2],3)
robust_peb_p <- round(comparison$`Pr(>F)`[2],3)
robust_peb_df <- comparison$Df[2]

```

We conducted a multiple linear regression model where dimensions of the
DEEP CTN scale, worldviews, and age were entered simultaneously to predict PEB. 

While interconnected worldviews explained a significant amount of unique variance, only the Emotional factor remained significant at a correct alpha to account for family-wise error (see Table 9). Including the covariates improved the fit of the model (F = `r robust_peb_f`(`r robust_peb_df`), p = `r robust_peb_p`).

**Table 9. Linear regression predicting PEB from DEEP CTN factors, Worldviews, and Age**

```{r robust PEB output, echo=FALSE, warning=FALSE}

full_join(peb_predict_table, peb_robust_table, by = "Variable", suffix = c("_1", "_2")) %>% 
  flextable() %>% 
  autofit() %>% 
  add_header_row(value = c(" ","Step 1", "Step 2"), colwidths = c(1,3,3)) %>% 
  set_header_labels(Variable = "Variable", `Partial R2_1` = "Partial R2", p_1 = "p", 
                    `std Beta (99% CI)_1` = "std Beta (99% CI)",
                    `Partial R2_2` = "Partial R2", p_2 = "p", 
                    `std Beta (99% CI)_2` = "std Beta (99% CI)") %>% 
  align(part = "header", align = "center") %>% 
  align(j = 2:7, align = "center") %>% 
  bold(i = 3:4, j = 3:4, part = "body") %>% #step 1
  bold(i = c(3,5), j = 5:7, part = "body") %>% #step 2
   bold(j = 1, i = 3:5) %>% 
    add_body_row(top = FALSE, 
               values = c("Model R2", peb_tot_var, robust_tot_var),
               colwidths = c(1,3,3)) %>% 
  align(j = 2:7, align = "right") %>%
     add_footer_lines(value = as_paragraph("Bold indicates significant p value and CI \n 
                                           To account for the familywise error rate of multiple tests, we used a corrected alpha of 0.025 as the critical p-value \n
                                           std Beta < 0.29 = small \n 
                                           std Beta < 0.49 = medium \n 
                                           std Beta > 0.50 = large")) 


```


### Hypothesis 5.B - Well-being

```{r Robustness Existing measures WB, eval=FALSE, warning=FALSE, include=FALSE}

robust_model_wb <-
      lm(WB ~ DeepCTN_z + ExpCTN_z + EmoCTN_z + PresCTN_z + 
             CNS_z + EIDR_z + 
            PI_interconnect_z + 
             age, data = val_data)


robust_anova_wb <-
     Anova(robust_model_wb, type = "II")


robust_r2 <-
     calc.relimp(robust_model_wb, type="lmg",
                 rela=F) #setting to T normalizes metrics to sum to 100%

robust_rvalues <- tibble(round(robust_r2$lmg,2)) #partial R2 of all variables
robust_pvalues <- tibble(round(robust_anova_wb$`Pr(>F)`,2),
                         .name_repair = "universal") #p values
vars <- tibble(c("deep_ctn_z", "exp_ctn_z", "emo_ctn_z", "presc_ctn_z", "CTN_Z", "EIDR_Z", "age"))

robust_tot_var<- round(robust_r2$R2, 2) #variance explained by model



#create table of R and P values
R2_incremental_wb_robust <- 
     bind_cols(vars, robust_rvalues, robust_pvalues[-8,])%>% 
     rename("variable" = `c(...)`, "Partial R2" = `round(robust_r2$lmg, 2)`, 
            "p" = `round.robust_anova_wb..Pr..F....2.`)
     
#plotting effect sizes
#https://www.mihiretukebede.com/posts/2020-09-30-2020-09-30-plotting-model-coefficients-in-a-forest-plot/
model_robustwB_output <- broom::tidy(robust_model_wb)
model_robustwB_conf <- broom::tidy(robust_model_wb, conf.int = T)

model_robustwB <- forestmangr::round_df(model_robustwB_conf, digits = 2)
model_robustwB <- model_robustwB[-1,] #remove the intercept 

coef_robustwB <- 
     coef(robust_model_wb)
ConfidenceInterval_robustwB <- 
     confint(robust_model_wb, level = 0.95)
coef_confint_robustwB <- 
     cbind(coef_robustwB, ConfidenceInterval_robustwB)%>% 
     as.data.frame()
coef_confint_robustwB <- 
     coef_confint_robustwB %>% 
     mutate(variable=rownames(coef_confint_robustwB))


coef_confint_robustwB <- 
     coef_confint_robustwB %>% 
     rename(c("std Beta" = "coef_robustwB",
              "lower_bound" = `2.5 %`, 
              "upper_bound" = `97.5 %`))

# Reorder variables
col_order <- c("variable", "std Beta", "lower_bound", "upper_bound")
coef_confint_robustwB <- 
     coef_confint_robustwB[, col_order] #reorder variables in the data frame

coef_confint_robustwB <- 
     coef_confint_robustwB %>% 
  mutate_if(is.numeric, round, digits = 2) # round numeric into two significant digits 

plot_model_robustwB <- coef_confint_robustwB[-1,] %>%  #remove row number 1 (The intercept) 
  ggplot(aes(x=reorder(variable, `std Beta`), y=`std Beta`)) +
  geom_point(shape = 15,
             size  = 4,
             position = "dodge", 
             color="black") + 
  geom_errorbar(aes(ymin  = lower_bound,
                    ymax  = upper_bound),
                size  = 1,
                position = "dodge", 
                color="turquoise4") +
  theme(axis.title = element_text(face = "bold")) +
  xlab("Variables") + ylab("Beta coeffecients with 95% CI") +
  coord_flip(ylim = c(-.5, .5)) + 
  geom_hline(yintercept = 0, color = "red", size = 1) +
   theme(axis.title = element_text(size = 17)) + 
  theme(axis.text = element_text(size = 14)) 

```

```{r Robustness dims onlys WB, echo=FALSE, include=FALSE, warning=FALSE}

robust_model_wb <-
      lm(WB ~ DeepCTN_z + ExpCTN_z + EmoCTN_z + PresCTN_z + 
           PI_interconnect_z + pol_z + age, data = val_data)


robust_anova_wb <-
     Anova(robust_model_wb, type = "II")


robust_r2 <-
     calc.relimp(robust_model_wb, type="lmg",
                 rela=F) #setting to T normalizes metrics to sum to 100%

robust_rvalues <- tibble(round(robust_r2$lmg,2)) #partial R2 of all variables
robust_pvalues <- tibble(round(robust_anova_wb$`Pr(>F)`,2),
                         .name_repair = "universal") #p values
vars <- tibble(c("deep_ctn_z", "exp_ctn_z", "emo_ctn_z", "presc_ctn_z", "PI_interconnect_z","pol_z", "age"))

robust_tot_var<- round(robust_r2$R2, 2) #variance explained by model



#create table of R and P values
R2_incremental_wb_robust <- 
     bind_cols(vars, robust_rvalues, robust_pvalues[-8,]) %>% 
     rename("variable" = `c(...)`, 
            "Partial R2" = `round(robust_r2$lmg, 2)`, 
            "p" = `round.robust_anova_wb..Pr..F....2.`)
     
#plotting effect sizes
#https://www.mihiretukebede.com/posts/2020-09-30-2020-09-30-plotting-model-coefficients-in-a-forest-plot/
model_robustwB_output <- broom::tidy(robust_model_wb)
model_robustwB_conf <- broom::tidy(robust_model_wb, conf.int = T)

model_robustwB <- forestmangr::round_df(model_robustwB_conf, digits = 2)
model_robustwB <- model_robustwB[-1,] #remove the intercept 

coef_robustwB <- 
     coef(robust_model_wb)
ConfidenceInterval_robustwB <- 
     confint(robust_model_wb, level = 0.95)
coef_confint_robustwB <- 
     cbind(coef_robustwB, ConfidenceInterval_robustwB)%>% 
     as.data.frame()
coef_confint_robustwB <- 
     coef_confint_robustwB %>% 
     mutate(variable=rownames(coef_confint_robustwB))


coef_confint_robustwB <- 
     coef_confint_robustwB %>% 
     rename(c("std Beta" = "coef_robustwB",
              "lower_bound" = `2.5 %`, 
              "upper_bound" = `97.5 %`))

# Reorder variables
col_order <- c("variable", "std Beta", "lower_bound", "upper_bound")
coef_confint_robustwB <- 
     coef_confint_robustwB[, col_order] #reorder variables in the data frame

coef_confint_robustwB <- 
     coef_confint_robustwB %>% 
  mutate_if(is.numeric, round, digits = 2)   # round numeric into two significant digits 

wb_robust_table <-
  bind_cols(coef_confint_robustwB[-1,], R2_incremental_wb_robust[,-1]) %>% 
  rename("Variable" = "variable") %>%
  mutate(`std Beta` = paste(`std Beta`, " (", lower_bound, " - ", upper_bound, ")"),
         Variable = case_when(Variable == "DeepCTN_z" ~ "Deep",
                              Variable == "ExpCTN_z" ~ "Experiential",
                              Variable == "EmoCTN_z" ~ "Emotional",
                              Variable == "PresCTN_z" ~ "Presence",
                              Variable == "PI_interconnect_z" ~ "Worldviews",
                              Variable == "pol_z" ~ "Politics",
                              Variable == "age" ~ "Age",
                              .default = paste(Variable))) %>% 
  dplyr::select(Variable, `Partial R2`, p, `std Beta`) %>%
  rename(`std Beta (99% CI)` = `std Beta`) %>% 
  as_tibble()




plot_model_robustwB <- coef_confint_robustwB[-1,] %>%  #remove row number 1 (The intercept) 
  ggplot(aes(x=reorder(variable, `std Beta`), y=`std Beta`)) +
  geom_point(shape = 15,
             size  = 4,
             position = "dodge", 
             color="black") + 
  geom_errorbar(aes(ymin  = lower_bound,
                    ymax  = upper_bound),
                size  = 1,
                position = "dodge", 
                color="turquoise4") +
  theme(axis.title = element_text(face = "bold")) +
  xlab("Variables") + ylab("Beta coeffecients with 95% CI") +
  coord_flip(ylim = c(-.5, .5)) + 
  geom_hline(yintercept = 0, color = "red", size = 1) +
   theme(axis.title = element_text(size = 17)) + 
  theme(axis.text = element_text(size = 14)) 

```

```{r robust anova table WB, echo=FALSE, message=FALSE, warning=FALSE}
#Compare models

comparison_wb <-
anova(dimensions_wb, robust_model_wb)

robust_wb_f <- round(comparison_wb$F[2],3)
robust_wb_p <- round(comparison_wb$`Pr(>F)`[2],3)
robust_wb_df <- comparison_wb$Df[2]

```

We conducted a multiple linear regression model where dimensions of the
DEEP CTN scale and age were entered simultaneously to predict
well-being. 

While interconnected worldviews and political ideology explained a significant amount of unique variance, only the Presence factor remained significant at a correct alpha to account for family-wise error (see Table 10). Including the covariates improved the fit of the model (F = `r robust_wb_f`(`r robust_wb_df`), p = `r robust_wb_p`).

**Table 10. Linear regression predicting Well-being from DEEP CTN factors, Worldviews, Politics, and Age**
```{r robust WB output, echo=FALSE, warning=FALSE}

full_join(wb_regression_table, wb_robust_table, by = "Variable", suffix = c("_1", "_2")) %>% 
  flextable() %>% 
  autofit() %>% 
  add_header_row(value = c(" ","Step 1", "Step 2"), colwidths = c(1,3,3)) %>% 
  set_header_labels(Variable = "Variable", `Partial R2_1` = "Partial R2", p_1 = "p", 
                    `std Beta (99% CI)_1` = "std Beta (99% CI)",
                    `Partial R2_2` = "Partial R2", p_2 = "p", 
                    `std Beta (99% CI)_2` = "std Beta (99% CI)") %>% 
  align(part = "header", align = "center") %>% 
  align(j = 2:7, align = "center") %>% 
  bold(i = c(1, 3,4), j = 2:4, part = "body") %>% #step 1
  bold(i = c(4,5,6), j = 5:6, part = "body") %>% #step 2 p
  bold(i = c(4,5,6), j = c(5,7), part = "body") %>% #step 2 p
   bold(j = 1, i = c(1,3,4,5,6,7)) %>% 
      add_body_row(top = FALSE, 
               values = c("Model R2", wb_tot_var, robust_tot_var),
               colwidths = c(1,3,3)) %>% 
  align(j = 2:7, align = "right") %>%
     add_footer_lines(value = as_paragraph("Bold indicates significant p value and CI \n 
                                           To account for the familywise error rate of multiple tests, we used a corrected alpha of 0.025 as the critical p-value. \n
                                           std Beta < 0.29 = small \n 
                                           std Beta < 0.49 = medium \n 
                                           std Beta > 0.50 = large")) 



```







[^1]: Two items had a kurtosis of 3.01 (Seeing a cleared forest is
    upsetting to me) and 3.02 (Every part of nature is sacred). These
    items were retained as they were extremely close to the cut-off and
    the Emotional scale was already reduced to 4 items.

# References
