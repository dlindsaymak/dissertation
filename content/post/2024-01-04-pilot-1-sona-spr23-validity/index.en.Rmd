---
title: 'PEB Validity (Pilot 1 SONA Spr23)'
author: Deb Lindsay
date: "`r Sys.Date()`"
slug: PEB_validity_sp23
categories:
  - Validity
tags:
  - Connection to Nature
  - DEEP CTN
  - Paper 1
  - Pro-Environmental Behavior
subtitle: ''
summary: ''
authors: []
lastmod: "`r Sys.Date()`"
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
output:
  blogdown::html_page:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
```

```{r Packages and Functions required, include=FALSE}

library(tidyverse) #base package that runs most functions
library(flextable) #tables
library(corrplot) #correlations
library(Hmisc) #correlations 
library(car) # Type 2 Anova
library(effectsize) #effect sizes
library(ggplot2) #plots
library(relaimpo) #calculates unique variance
```

```{r loading data, include=FALSE}
CFA1 <- 
     read_csv("../2023-12-14-cfa-data/CFApilot1SONA_data_clean.csv")

#pull out non-binary participants as the n is not big enough to run analyses
#removed 9 participants
CFA1 <-    
 CFA1 %>% 
     filter(gender == "Woman" | gender == "Man") 

#create new measure based on CFA pilot 1
val_data <-
     CFA1 %>% 
     mutate(deep_ctn = (DEEPCTN_s_1 + 
                             DEEPCTN_s_2 +
                             DEEPCTN_s_3 +
                             DEEPCTN_s_7 +
                             DEEPCTN_s_10 +
                             DEEPCTN_s_8 +
                             DEEPCTN_s_4 +
                             DEEPCTN_s_6 +
                             DEEPCTN_s_9)/9,
            deep_ctn_z = as.numeric(scale(deep_ctn, 
                                          center = T, scale = T)),
            exp_CTN = (DEEPCTN_ex_4 +
                            DEEPCTN_ex_5 +
                            DEEPCTN_ex_6 +
                            DEEPCTN_ex_8 +
                            DEEPCTN_ex_1 +
                            DEEPCTN_ex_2 +
                            DEEPCTN_ex_3)/7,
            exp_ctn_z = as.numeric(scale(exp_CTN, 
                                         center = T, scale = T)),
            
            emo_CTN = (DEEPCTN_emo_1 +
                            DEEPCTN_emo_2 +
                            DEEPCTN_emo_4 +
                            DEEPCTN_em_6)/4,
            emo_ctn_z = as.numeric(scale(emo_CTN,
                                         center = T, scale = T)),
            
            presc_CTN = (DEEPCTN_m_1 +
                              DEEPCTN_m_2 +
                              DEEPCTN_m_3 +
                              DEEPCTN_m_4 +
                              DEEPCTN_m_5 +
                              DEEPCTN_m_6)/6,
            presc_ctn_z = as.numeric(scale(presc_CTN, 
                                           center = T, scale = T)),
            
            CTN_overall = (DEEPCTN_s_1 + 
                             DEEPCTN_s_2 +
                             DEEPCTN_s_3 +
                             DEEPCTN_s_7 +
                             DEEPCTN_s_10 +
                             DEEPCTN_s_8 +
                             DEEPCTN_s_4 +
                             DEEPCTN_s_6 +
                             DEEPCTN_s_9 +
                              DEEPCTN_ex_4 +
                              DEEPCTN_ex_5 +
                              DEEPCTN_ex_6 +
                              DEEPCTN_ex_8 +
                              DEEPCTN_ex_1 +
                              DEEPCTN_ex_2 +
                              DEEPCTN_ex_3 +
                              DEEPCTN_emo_1 +
                              DEEPCTN_emo_2 +
                              DEEPCTN_emo_4 +
                              DEEPCTN_em_6 +
                                DEEPCTN_m_1 +
                              DEEPCTN_m_2 +
                              DEEPCTN_m_3 +
                              DEEPCTN_m_4 +
                              DEEPCTN_m_5 +
                              DEEPCTN_m_6)/26,
            CTN_overall_z = as.numeric(scale(CTN_overall, 
                                             center = T, scale = T)))

```

Pilot data collected during the Spring quarter (2023) on SONA students. This was piloting the CFA that will be run on Prolific participants Jan 2024. See [DEEP CTN CFA](/post/cfa_sp23/) for descriptives from this sample.

# Convergent Validity

```{r Validation, include=FALSE}

cormatrix <- 
     val_data %>% 
          dplyr::select(CTN_overall_z,
                 deep_ctn_z,
                 exp_ctn_z,
                 emo_ctn_z,
                 presc_ctn_z,
                 CNS_Z,
                 EIDR_Z,
                 PEB_Z,
                 PI_me_Z,
                 PI_hierarchy_Z,
                 PI_connect_Z) %>% 
          as.matrix() 
            
correlations <-
     rcorr(cormatrix, type = "spearman")

corp <- 
     cor.mtest(cormatrix)

#Corplot
# I edited the Corplot function to move the significance stars up
# https://stackoverflow.com/questions/49695113/changing-the-position-of-the-signifigance-pch-symbols-in-corrplot
# 
# trace(corrplot, edit = T)
# 
# Then replace on line 443
#   place_points = function(sig.locs, point) {
#    text(pos.pNew[, 1][sig.locs], pos.pNew[, 2][sig.locs], 
#        labels = point, col = pch.col, cex = pch.cex, 
#        lwd = 2)
# 
#  with:
# adjust text(X,Y ...) according to your needs, here +0.25 is added to the Y-position    
# 
#    place_points = function(sig.locs, point) {
#      text(pos.pNew[, 1][sig.locs], (pos.pNew[, 2][sig.locs])+0.25, 
#           labels = point, col = pch.col, cex = pch.cex, 
#          lwd = 2)




```

```{r Correlation plot, echo=FALSE, include=TRUE, out.width="100%"}
#corrplot(correlations$r,
#         type = "upper",
#         method = "color",
#         addCoef.col = "black",
#         number.cex = .75,
#         outline = T,
#         addgrid.col = "white",
#         order = "original",
#         tl.cex = 1,
#         tl.col = "black",
#         tl.srt = 35,
#         cl.pos = "n",
#         p.mat = corp$p,
#         sig.level = c(0.001, 0.01, 0.05),
#         insig = "label_sig",
#         pch.cex = .75)

nm = rownames(correlations$r)
m = t(combn(nm, 2))
d = cbind(data.frame(m), R = correlations$r[m], P = correlations$P[m])
d$label = round(d$R, 2)
d$label[d$P < 0.001] = paste0(d$label[d$P < 0.001], "\n**")
d$X1 = factor(d$X1, nm)
d$X2 = factor(d$X2, rev(nm))

graphics.off()
validation_plot <- 
  ggplot(d, aes(X1, X2, fill = R, label = label)) +
    geom_tile(color = "white") +
    scale_fill_viridis_c() +
    geom_text(color = ifelse(d$R > 0.35, "black", "white"), size = 2) +
    theme_bw() +
    coord_equal() +
     theme(axis.text.x = element_text(angle = 45, hjust = 1))



```

```{r validation plot 2, echo=FALSE}
print(validation_plot)

```

::: {style="color: blue"}
*Zero-order correlation betweens dimensions of CTN and existing scales:*

-   *Deep*
    -   *CNS: .73\*\* (strong)*
    -   *EIDR: .61\*\* (moderate)*
-   *Experiential*
    -   *CNS: .57\*\* (moderate)*
    -   *EIDR: .77\*\* (strong)*
-   *Emotional*
    -   *CNS: .45\*\* (moderate)*
    -   *EIDR: .54\*\* (moderate)*
-   *Presence*
    -   *CNS: .46\*\* (moderate)*
    -   *EIDR: .50\*\* (moderate)*
-   *Overall CTN*
    -   *CNS: .71\*\* (strong)*
    -   *EIDR: .74\*\* (strong)*
:::

# Predictive Validity

::: {style="color: blue"}
*Linear regression model where dimensions of the DEEP CTN scale were entered simultaneously to predict PEB.*

*Unique variance explained:*

-   *Deep CTN: 9%*
-   *Emotional CTN: 7%*
-   *Presence CTN: 7%*

*Note: because overall CTN was highly intercorrelated with Deep and Emotional, it was left out and only the four dimensions were included.*
:::

```{r linear regression with only dimensions predicting PEB, echo=FALSE, message=FALSE, warning=FALSE}

dimensions_peb <-
      lm(PEB_Z ~ deep_ctn_z + exp_ctn_z + emo_ctn_z + presc_ctn_z, 
         data = val_data)

dimensions_peb_anova <-
     Anova(dimensions_peb, type = "II")

peb_r2 <-
     calc.relimp(dimensions_peb, type="lmg",
                 rela=F) #setting to T normalizes metrics to sum to 100%

p_vars <- c("deep_ctn_z", "exp_ctn_z", "emo_ctn_z", "presc_ctn_z")
peb_rvalues <- tibble(round(peb_r2$lmg,2)) #partial R2 of all variables
peb_pvalues <- tibble(round(dimensions_peb_anova$`Pr(>F)`,2),
                         .name_repair = "universal") #p values

peb_tot_var<-round(peb_r2$R2, 2) #variance explained by model



#create table of R and P values
R2_peb_table <- 
     bind_cols(p_vars,peb_rvalues, peb_pvalues[-5,]) %>% 
     rename("variable" = `...1`, "Partial R2" = `round(peb_r2$lmg, 2)`, 
            "p" = `round.dimensions_peb_anova..Pr..F....2.`)





#plotting effect sizes
#https://www.mihiretukebede.com/posts/2020-09-30-2020-09-30-plotting-model-coefficients-in-a-forest-plot/
dim_only_output <- broom::tidy(dimensions_peb)
dim_only_conf <- broom::tidy(dimensions_peb, conf.int = T)

model_dim_only <- forestmangr::round_df(dim_only_output, digits = 2)
model_dim_only <- model_dim_only[-1,] #remove the intercept 

coef_dim_only <- 
     coef(dimensions_peb)
ConfidenceInterval_dim_only <- 
     confint(dimensions_peb, level = 0.95)
coef_confint_dim_only <- 
     cbind(coef_dim_only, ConfidenceInterval_dim_only)%>% 
     as.data.frame()
coef_confint_dim_only <- 
     coef_confint_dim_only %>% 
     mutate(variable=rownames(coef_confint_dim_only))


coef_confint_dim_only <- 
     coef_confint_dim_only %>% 
     rename(c("std Beta" = "coef_dim_only",
              "lower_bound" = `2.5 %`, 
              "upper_bound" = `97.5 %`))

# Reorder variables
col_order <- c("variable", "std Beta", "lower_bound", "upper_bound")
coef_confint_dim_only <- 
     coef_confint_dim_only[, col_order] #reorder variables in the data frame

coef_confint_dim_only <- 
     coef_confint_dim_only %>% 
  mutate_if(is.numeric, round, digits = 2) # round numeric into two significant digits 

plot_model_dim_only <- coef_confint_dim_only[-1,] %>%  #remove row number 1 (The intercept) 
  ggplot(aes(x=reorder(variable, `std Beta`), y=`std Beta`)) +
  geom_point(shape = 15,
             size  = 4,
             position = "dodge", 
             color="black") + 
  geom_errorbar(aes(ymin  = lower_bound,
                    ymax  = upper_bound),
                size  = 1,
                position = "dodge", 
                color="turquoise4") +
  theme(axis.title = element_text(face = "bold")) +
  xlab("Variables") + ylab("Beta coeffecients with 95% CI") +
  coord_flip(ylim = c(-.5, .5)) + 
  geom_hline(yintercept = 0, color = "red", size = 1) +
   theme(axis.title = element_text(size = 17)) + 
  theme(axis.text = element_text(size = 14)) 

```

```{r dimonly output, echo=FALSE, message=FALSE, warning=FALSE}


bind_cols(coef_confint_dim_only[-1,], R2_peb_table[,-1]) %>% 
     relocate(c(`Partial R2`, p), .after = variable) %>% 
     flextable() %>% 
     bold(~p < .05, 1:3) %>% 
     bold(~lower_bound > 0, c(1,4,5,6)) %>% 
     footnote(i = 1, j = 4,
              value = as_paragraph("< 0.29 = small; 
                                   0.30-0.49 = medium;
                                   > 0.50 = large"),
              ref_symbols = "*",
              part = "header") %>% 
  autofit()




```

Total variance explained by the model = `r paste(peb_tot_var)`

```{r ploteffectspredict, echo=FALSE, message=FALSE, warning=FALSE}

plot_model_dim_only

```

# Incremental Validity

::: {style="color: blue"}
*Linear regression model where dimensions of the DEEP CTN scale and the existing CTN measures (CNS and EIDR) were entered simultaneously to predict PEB.*

*Unique variance explained:*

-   *Deep CTN: became NS*
-   *Emotional CTN: 6% (less 1%)*
-   *Presence CTN: 6% (less 1%)*

*Note: because overall CTN was highly intercorrelated with Deep and Emotional, it was left out and only the four dimensions were included.*
:::

```{r predictive validity PEB,include=FALSE, warning=FALSE}

val_data <-
     val_data %>% 
  filter(!is.na(SES_peers_z)) %>% 
     mutate(politics = (politics_overall_Z + politics_economic_z +
                             politics_social_z)/3,
            ses = (SES_family_z + SES_peers_z)/2)

model_peb <- 
     lm(PEB_Z ~ deep_ctn_z + exp_ctn_z + emo_ctn_z + presc_ctn_z +
             CNS_Z + EIDR_Z, data = val_data)

anova_model_peb <-
     Anova(model_peb, type = "II")


incremental_r2 <-
     calc.relimp(model_peb, type="lmg",
                 rela=F) #setting to T normalizes metrics to sum to 100%

incremental_vars <- c("deep_ctn_z", "exp_ctn_z", "emo_ctn_z", "presc_ctn_z", "CTN_Z", "EIDR_Z")
incremental_rvalues <- tibble(round(incremental_r2$lmg,2)) #partial R2 of all variables
incremental_pvalues <- tibble(round(anova_model_peb$`Pr(>F)`,2),
                         .name_repair = "universal") #p values

inc_tot_var <-round(incremental_r2$R2, 2) #variance explained by model



#create table of R and P values
R2_incremental_table <- 
     bind_cols(incremental_vars, incremental_rvalues, incremental_pvalues[-7,]) %>% 
     rename("variable" = `...1`, "Partial R2" = `round(incremental_r2$lmg, 2)`, 
            "p" = `round.anova_model_peb..Pr..F....2.`)







#plotting effect sizes
#https://www.mihiretukebede.com/posts/2020-09-30-2020-09-30-plotting-model-coefficients-in-a-forest-plot/
model_peb_output <- broom::tidy(model_peb)
model_peb_conf <- broom::tidy(model_peb, conf.int = T)

model_peb_out <- forestmangr::round_df(model_peb_conf, digits = 2)
model_peb_out <- model_peb_out[-1,] #remove the intercept 

coef_peb <- 
     coef(model_peb)
ConfidenceInterval_peb <- 
     confint(model_peb, level = 0.95)
coef_confint_peb <- 
     cbind(coef_peb, ConfidenceInterval_peb)%>% 
     as.data.frame()
coef_confint_peb <- 
     coef_confint_peb %>% 
     mutate(variable=rownames(coef_confint_peb))


coef_confint_peb <- 
     coef_confint_peb %>% 
     rename(c("std Beta" = "coef_peb",
              "lower_bound" = `2.5 %`, 
              "upper_bound" = `97.5 %`))

# Reorder variables
col_order <- c("variable", "std Beta", "lower_bound", "upper_bound")
coef_confint_peb <- 
     coef_confint_peb[, col_order] #reorder variables in the data frame

coef_confint_peb <- 
     coef_confint_peb %>% 
  mutate_if(is.numeric, round, digits = 2) # round numeric into two significant digits 

plot_model_peb <- coef_confint_peb[-1,] %>%  #remove row number 1 (The intercept) 
  ggplot(aes(x=reorder(variable, `std Beta`), y=`std Beta`)) +
     geom_hline(yintercept = 0, color = "red", size = 1) +
  geom_point(shape = 15,
             size  = 4,
             position = "dodge", 
             color="black") + 
  geom_errorbar(aes(ymin  = lower_bound,
                    ymax  = upper_bound),
                size  = 1,
                position = "dodge", 
                color="turquoise4") +
  theme(axis.title = element_text(face = "bold")) +
  xlab("Variables") + ylab("Beta coeffecients with 95% CI") +
  coord_flip(ylim = c(-.5, .5)) + 
  
   theme(axis.title = element_text(size = 17)) + 
  theme(axis.text = element_text(size = 14)) 
```

```{r model PEB plots, echo=FALSE, warning=FALSE}

bind_cols(coef_confint_peb[-1,], R2_incremental_table[,-1]) %>% 
     relocate(c(`Partial R2`, p), .after = variable) %>% 
     flextable() %>% 
     bold(~p < .05, 1:3) %>% 
     bold(~lower_bound > 0, c(1,4,5,6))%>% 
     footnote(i = 1, j = 4,
              value = as_paragraph("< 0.29 = small; 
                                   0.30-0.49 = medium;
                                   > 0.50 = large"),
              ref_symbols = "*",
              part = "header") %>% 
  autofit()





```

Total variance explained by the model = `r paste(inc_tot_var)`

```{r effectplotincremental, echo=FALSE, message=FALSE, warning=FALSE}
plot_model_peb
```

# Robustness

Covariates tested on the basis of past research finding relationships between them and PEB

-   Primal Beliefs - Everything is Connected
-   Politics (more liberal = more PEB)
-   Gender (female more likely to engage in PEB)
-   SES (higher SES more likely to engage in PEB)
-   Locus of Control (more locus of control = more PEB)

[*Note: other covariates may be included based on a zero-order Spearman correlation matrix that includes all variables in the study. If a variable is...*]{style="color: red"}

a.  [*strongly correlated with the any of the dependent variable cited in Prediction 4 above AND*]{style="color: red"}
b.  [*weakly correlated with the Deep CTN Scale*]{style="color: red"}

[*...its inclusion in the model will reduce variance in the dependent variable and therefore enhance the likelihood of seeing significant effects of the state-FFMQ. Further, if an additional variable is...*]{style="color: red"}

c.  [*strongly correlated with BOTH any DV (in Prediction 4 above) AND*]{style="color: red"}
d.  [*the Deep CTN Scale,*]{style="color: red"}

[*...its inclusion in the model will address potential mediating effects regarding the relationship between the Deep CTN Scale and a DV of interest. In either case this would suggest it's important to include as a covariate.*]{style="color: red"}

These include

-   Politics (r = .19\*\* with PEB & r = .18\*\* to .23\*\* with DEEP CTN dimensions)

-   Primal Beliefs - The world is interconnect (r = .21\*\* with PEB & r = .22\*\* to .38\*\* with DEEP CTN dimensions)

```{r Robustness Covariates, echo=FALSE, include=FALSE}

val_data <-
  val_data %>% 
  mutate(gender = case_when(gender == "Woman" ~ 0,
                            gender == "Man" ~ 1))


allvarscordata <- 
     val_data %>% 
         dplyr::select(CTN_overall_z,
                 deep_ctn_z,
                 exp_ctn_z,
                 emo_ctn_z,
                 presc_ctn_z,
                 CNS_Z,
                 EIDR_Z,
                 PEB_Z,
                 PI_me_Z,
                 PI_hierarchy_Z,
                 PI_connect_Z,
                 politics,
                 gender, #0 = female, 1=male
                 ses,
                 LOC_Z)  %>% 
          as.matrix()


     

allvarscorrelation <-
     rcorr(allvarscordata, type = "spearman")

allvarscorp <- 
     cor.mtest(allvarscordata)

nm = rownames(allvarscorrelation$r)
m = t(combn(nm, 2))
d = cbind(data.frame(m), R = allvarscorrelation$r[m], P = allvarscorrelation$P[m])
d$label = round(d$R, 2)
d$label[d$P < 0.001] = paste0(d$label[d$P < 0.001], "\n**")
d$X1 = factor(d$X1, nm)
d$X2 = factor(d$X2, rev(nm))

graphics.off()
robustness_plot <- 
  ggplot(d, aes(X1, X2, fill = R, label = label)) +
    geom_tile(color = "white") +
    scale_fill_viridis_c() +
    geom_text(color = ifelse(d$R > 0.35, "black", "white"), size = 2) +
    theme_bw() +
    coord_equal() +
     theme(axis.text.x = element_text(angle = 45, hjust = 1))



```

```{r full zero-order correlation, echo=FALSE}
print(robustness_plot)
```

::: {style="color: blue"}
*Linear regression model where dimensions of the DEEP CTN scale and existing CTN measures (CNS and EIDR) were entered simultaneously at Step 1 to predict PEB. Then at Step 2 covariates (Primal beliefs - connectedness and politics) were added.*

*Unique variance explained at Step 2 (after controlling for covariates)*

-   *Emotional CTN: 5% (less 1%)*
-   *Presence CTN: 5% (less 1%)*
-   *CNS: 5% (but CI included 0)*

*Adding covariates did not improve the fit of the model*

*Note: because overall CTN was highly intercorrelated with Deep and Emotional, it was left out and only the four dimensions were included.*
:::

```{r Robustness Existing measures, echo=FALSE, include=FALSE, warning=FALSE}
#dummycode gender
val_data <-
val_data %>% 
     mutate(gender_dummy = as.numeric(gender)) 


robust_model_peb <-
      lm(PEB_Z ~ deep_ctn_z + exp_ctn_z + emo_ctn_z + presc_ctn_z +
             CNS_Z + EIDR_Z + 
             PI_connect_Z + politics, data = val_data)

robust_anova_peb <-
     Anova(robust_model_peb, type = "II")


robust_r2 <-
     calc.relimp(robust_model_peb, type="lmg",
                 rela=F) #setting to T normalizes metrics to sum to 100%

robust_rvalues <- tibble(round(robust_r2$lmg,2)) #partial R2 of all variables
robust_pvalues <- tibble(round(robust_anova_peb$`Pr(>F)`,2),
                         .name_repair = "universal") #p values
vars <- tibble(c("deep_ctn_z", "exp_ctn_z", "emo_ctn_z", "presc_ctn_z", "CTN_Z", "EIDR_Z", "PI_connect_Z", "politics"))

robust_tot_var<- round(robust_r2$R2, 2) #variance explained by model



#create table of R and P values
R2_incremental_peb_robust <- 
     bind_cols(vars, robust_rvalues, robust_pvalues[-9,])%>% 
     rename("variable" = `c(...)`, "Partial R2" = `round(robust_r2$lmg, 2)`, 
            "p" = `round.robust_anova_peb..Pr..F....2.`)
     
#plotting effect sizes
#https://www.mihiretukebede.com/posts/2020-09-30-2020-09-30-plotting-model-coefficients-in-a-forest-plot/
model_robustPEB_output <- broom::tidy(robust_model_peb)
model_robustPEB_conf <- broom::tidy(robust_model_peb, conf.int = T)

model_robustPEB <- forestmangr::round_df(model_robustPEB_conf, digits = 2)
model_robustPEB <- model_robustPEB[-1,] #remove the intercept 

coef_robustPEB <- 
     coef(robust_model_peb)
ConfidenceInterval_robustPEB <- 
     confint(robust_model_peb, level = 0.95)
coef_confint_robustPEB <- 
     cbind(coef_robustPEB, ConfidenceInterval_robustPEB)%>% 
     as.data.frame()
coef_confint_robustPEB <- 
     coef_confint_robustPEB %>% 
     mutate(variable=rownames(coef_confint_robustPEB))


coef_confint_robustPEB <- 
     coef_confint_robustPEB %>% 
     rename(c("std Beta" = "coef_robustPEB",
              "lower_bound" = `2.5 %`, 
              "upper_bound" = `97.5 %`))

# Reorder variables
col_order <- c("variable", "std Beta", "lower_bound", "upper_bound")
coef_confint_robustPEB <- 
     coef_confint_robustPEB[, col_order] #reorder variables in the data frame

coef_confint_robustPEB <- 
     coef_confint_robustPEB %>% 
  mutate_if(is.numeric, round, digits = 2) # round numeric into two significant digits 

plot_model_robustPEB <- coef_confint_robustPEB[-1,] %>%  #remove row number 1 (The intercept) 
  ggplot(aes(x=reorder(variable, `std Beta`), y=`std Beta`)) +
  geom_point(shape = 15,
             size  = 4,
             position = "dodge", 
             color="black") + 
  geom_errorbar(aes(ymin  = lower_bound,
                    ymax  = upper_bound),
                size  = 1,
                position = "dodge", 
                color="turquoise4") +
  theme(axis.title = element_text(face = "bold")) +
  xlab("Variables") + ylab("Beta coeffecients with 95% CI") +
  coord_flip(ylim = c(-.5, .5)) + 
  geom_hline(yintercept = 0, color = "red", size = 1) +
   theme(axis.title = element_text(size = 17)) + 
  theme(axis.text = element_text(size = 14)) 

```

```{r robust PEB output, echo=FALSE, warning=FALSE}


bind_cols(coef_confint_robustPEB[-1,], R2_incremental_peb_robust[,-1]) %>% 
     relocate(c(`Partial R2`, p), .after = variable) %>% 
     flextable() %>% 
     bold(~p < .05, 1:3) %>% 
     bold(~lower_bound > 0, c(1,4,5,6))%>% 
     footnote(i = 1, j = 4,
              value = as_paragraph("< 0.29 = small; 
                                   0.30-0.49 = medium;
                                   > 0.50 = large"),
              ref_symbols = "*",
              part = "header") %>% 
  autofit()







```

Total variance explained by the model = `r paste(robust_tot_var)`

```{r effectplotrobust, echo=FALSE, message=FALSE, warning=FALSE}
plot_model_robustPEB
```

## Comparing Incremental and Robust models

Adding robust variables did not improve the fit of the model above the variables in the incremental validity model

```{r robust anova table, echo=FALSE, message=FALSE, warning=FALSE}
#Compare models

model_names <- c("Incremental", "Robust")

comparison <-
anova(model_peb, robust_model_peb)

bind_cols(model_names, comparison) %>% 
  flextable() %>% 
  autofit()
```
